{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e9f613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 1 GPU(s) available: ['/physical_device:GPU:0']\n",
      "차량 외관 이상치 필터링 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "클래스별 필터링: 100%|██████████| 396/396 [37:04<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 전체 이미지 수: 33137\n",
      "✅ 필터링된 차량 외관 이미지 수: 20022\n",
      "🧼 이상치 제거 완료. 정제 비율: 60.42%\n",
      "\n",
      "### Fold 1 시작 ###\n",
      "Epoch 1/15\n",
      "667/667 [==============================] - 285s 207ms/step - loss: 3.4425 - accuracy: 0.3617 - val_loss: 3.5410 - val_accuracy: 0.2576\n",
      "Epoch 2/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 1.1479 - accuracy: 0.7056 - val_loss: 2.0320 - val_accuracy: 0.4530\n",
      "Epoch 3/15\n",
      "667/667 [==============================] - 61s 89ms/step - loss: 0.5029 - accuracy: 0.8662 - val_loss: 1.4907 - val_accuracy: 0.5845\n",
      "Epoch 4/15\n",
      "667/667 [==============================] - 61s 89ms/step - loss: 0.2986 - accuracy: 0.9184 - val_loss: 1.0644 - val_accuracy: 0.6972\n",
      "Epoch 5/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.2055 - accuracy: 0.9432 - val_loss: 0.8718 - val_accuracy: 0.7551\n",
      "Epoch 6/15\n",
      "667/667 [==============================] - 62s 89ms/step - loss: 0.1543 - accuracy: 0.9568 - val_loss: 0.9210 - val_accuracy: 0.7546\n",
      "Epoch 7/15\n",
      "667/667 [==============================] - 61s 89ms/step - loss: 0.1262 - accuracy: 0.9656 - val_loss: 0.9878 - val_accuracy: 0.7454\n",
      "Epoch 8/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.1117 - accuracy: 0.9689 - val_loss: 0.9597 - val_accuracy: 0.7384\n",
      "Epoch 9/15\n",
      "667/667 [==============================] - 61s 89ms/step - loss: 0.0889 - accuracy: 0.9771 - val_loss: 0.7942 - val_accuracy: 0.8001\n",
      "Epoch 10/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.0797 - accuracy: 0.9799 - val_loss: 0.7554 - val_accuracy: 0.8168\n",
      "Epoch 11/15\n",
      "667/667 [==============================] - 141s 208ms/step - loss: 0.0702 - accuracy: 0.9823 - val_loss: 0.7687 - val_accuracy: 0.8166\n",
      "Epoch 12/15\n",
      "667/667 [==============================] - 69s 92ms/step - loss: 0.0721 - accuracy: 0.9811 - val_loss: 0.6893 - val_accuracy: 0.8251\n",
      "Epoch 13/15\n",
      "667/667 [==============================] - 61s 89ms/step - loss: 0.0592 - accuracy: 0.9837 - val_loss: 0.7318 - val_accuracy: 0.8186\n",
      "Epoch 14/15\n",
      "667/667 [==============================] - 62s 91ms/step - loss: 0.0539 - accuracy: 0.9861 - val_loss: 0.6371 - val_accuracy: 0.8558\n",
      "Epoch 15/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.0535 - accuracy: 0.9851 - val_loss: 0.7240 - val_accuracy: 0.8341\n",
      "\n",
      "### Fold 2 시작 ###\n",
      "Epoch 1/15\n",
      "667/667 [==============================] - 66s 89ms/step - loss: 3.4294 - accuracy: 0.3675 - val_loss: 3.6940 - val_accuracy: 0.2424\n",
      "Epoch 2/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 1.1421 - accuracy: 0.7109 - val_loss: 2.1035 - val_accuracy: 0.4328\n",
      "Epoch 3/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.4895 - accuracy: 0.8689 - val_loss: 1.3506 - val_accuracy: 0.6179\n",
      "Epoch 4/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.2971 - accuracy: 0.9196 - val_loss: 1.1040 - val_accuracy: 0.6874\n",
      "Epoch 5/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 1.0128 - val_accuracy: 0.7269\n",
      "Epoch 6/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.1601 - accuracy: 0.9563 - val_loss: 0.9825 - val_accuracy: 0.7354\n",
      "Epoch 7/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.1242 - accuracy: 0.9663 - val_loss: 0.8388 - val_accuracy: 0.7864\n",
      "Epoch 8/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.1030 - accuracy: 0.9737 - val_loss: 0.8093 - val_accuracy: 0.7989\n",
      "Epoch 9/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.1012 - accuracy: 0.9723 - val_loss: 0.8362 - val_accuracy: 0.7964\n",
      "Epoch 10/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.0841 - accuracy: 0.9788 - val_loss: 0.7538 - val_accuracy: 0.8153\n",
      "Epoch 11/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.0780 - accuracy: 0.9792 - val_loss: 0.8030 - val_accuracy: 0.8096\n",
      "Epoch 12/15\n",
      "667/667 [==============================] - 61s 89ms/step - loss: 0.0751 - accuracy: 0.9806 - val_loss: 0.8515 - val_accuracy: 0.7994\n",
      "Epoch 13/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.0667 - accuracy: 0.9834 - val_loss: 0.7361 - val_accuracy: 0.8306\n",
      "Epoch 14/15\n",
      "667/667 [==============================] - 62s 89ms/step - loss: 0.0573 - accuracy: 0.9861 - val_loss: 0.7035 - val_accuracy: 0.8326\n",
      "Epoch 15/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.0575 - accuracy: 0.9843 - val_loss: 0.8865 - val_accuracy: 0.8131\n",
      "\n",
      "### Fold 3 시작 ###\n",
      "Epoch 1/15\n",
      "667/667 [==============================] - 69s 92ms/step - loss: 3.3903 - accuracy: 0.3673 - val_loss: 3.6240 - val_accuracy: 0.2694\n",
      "Epoch 2/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 1.1499 - accuracy: 0.7092 - val_loss: 2.0904 - val_accuracy: 0.4500\n",
      "Epoch 3/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 0.5037 - accuracy: 0.8661 - val_loss: 1.3852 - val_accuracy: 0.6007\n",
      "Epoch 4/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.2900 - accuracy: 0.9217 - val_loss: 1.1107 - val_accuracy: 0.6927\n",
      "Epoch 5/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.1982 - accuracy: 0.9443 - val_loss: 1.0461 - val_accuracy: 0.7221\n",
      "Epoch 6/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 0.1532 - accuracy: 0.9581 - val_loss: 0.9248 - val_accuracy: 0.7549\n",
      "Epoch 7/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.1148 - accuracy: 0.9689 - val_loss: 0.8299 - val_accuracy: 0.7829\n",
      "Epoch 8/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.1013 - accuracy: 0.9738 - val_loss: 0.8216 - val_accuracy: 0.7799\n",
      "Epoch 9/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.0914 - accuracy: 0.9760 - val_loss: 0.8652 - val_accuracy: 0.7916\n",
      "Epoch 10/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.0861 - accuracy: 0.9786 - val_loss: 0.8405 - val_accuracy: 0.8021\n",
      "Epoch 11/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.0750 - accuracy: 0.9808 - val_loss: 0.7234 - val_accuracy: 0.8276\n",
      "Epoch 12/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 0.0745 - accuracy: 0.9809 - val_loss: 0.7309 - val_accuracy: 0.8191\n",
      "Epoch 13/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.0644 - accuracy: 0.9848 - val_loss: 0.8088 - val_accuracy: 0.8193\n",
      "Epoch 14/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 0.0564 - accuracy: 0.9850 - val_loss: 0.6670 - val_accuracy: 0.8473\n",
      "Epoch 15/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 0.0623 - accuracy: 0.9846 - val_loss: 0.7562 - val_accuracy: 0.8303\n",
      "\n",
      "### Fold 4 시작 ###\n",
      "Epoch 1/15\n",
      "667/667 [==============================] - 68s 92ms/step - loss: 3.4885 - accuracy: 0.3538 - val_loss: 3.8985 - val_accuracy: 0.2467\n",
      "Epoch 2/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 1.1863 - accuracy: 0.7013 - val_loss: 2.2378 - val_accuracy: 0.4191\n",
      "Epoch 3/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.5222 - accuracy: 0.8617 - val_loss: 1.6016 - val_accuracy: 0.5564\n",
      "Epoch 4/15\n",
      "667/667 [==============================] - 62s 91ms/step - loss: 0.3101 - accuracy: 0.9140 - val_loss: 1.5295 - val_accuracy: 0.5969\n",
      "Epoch 5/15\n",
      "667/667 [==============================] - 61s 89ms/step - loss: 0.2108 - accuracy: 0.9450 - val_loss: 1.0793 - val_accuracy: 0.7156\n",
      "Epoch 6/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 0.1535 - accuracy: 0.9593 - val_loss: 1.0154 - val_accuracy: 0.7438\n",
      "Epoch 7/15\n",
      "667/667 [==============================] - 63s 92ms/step - loss: 0.1295 - accuracy: 0.9663 - val_loss: 0.8169 - val_accuracy: 0.7868\n",
      "Epoch 8/15\n",
      "667/667 [==============================] - 64s 92ms/step - loss: 0.1064 - accuracy: 0.9714 - val_loss: 0.8240 - val_accuracy: 0.7938\n",
      "Epoch 9/15\n",
      "667/667 [==============================] - 63s 92ms/step - loss: 0.0933 - accuracy: 0.9761 - val_loss: 0.8066 - val_accuracy: 0.7908\n",
      "Epoch 10/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.0911 - accuracy: 0.9758 - val_loss: 0.7487 - val_accuracy: 0.8055\n",
      "Epoch 11/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 0.0838 - accuracy: 0.9774 - val_loss: 0.8840 - val_accuracy: 0.7818\n",
      "Epoch 12/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 0.0728 - accuracy: 0.9817 - val_loss: 0.7916 - val_accuracy: 0.8188\n",
      "Epoch 13/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 0.0643 - accuracy: 0.9829 - val_loss: 0.8427 - val_accuracy: 0.8235\n",
      "Epoch 14/15\n",
      "667/667 [==============================] - 65s 94ms/step - loss: 0.0658 - accuracy: 0.9842 - val_loss: 0.7449 - val_accuracy: 0.8365\n",
      "Epoch 15/15\n",
      "667/667 [==============================] - 67s 97ms/step - loss: 0.0647 - accuracy: 0.9841 - val_loss: 0.7309 - val_accuracy: 0.8260\n",
      "\n",
      "### Fold 5 시작 ###\n",
      "Epoch 1/15\n",
      "667/667 [==============================] - 88s 119ms/step - loss: 3.4800 - accuracy: 0.3568 - val_loss: 3.6867 - val_accuracy: 0.2537\n",
      "Epoch 2/15\n",
      "667/667 [==============================] - 94s 130ms/step - loss: 1.1509 - accuracy: 0.7074 - val_loss: 2.0452 - val_accuracy: 0.4536\n",
      "Epoch 3/15\n",
      "667/667 [==============================] - 66s 96ms/step - loss: 0.4931 - accuracy: 0.8691 - val_loss: 1.3361 - val_accuracy: 0.6156\n",
      "Epoch 4/15\n",
      "667/667 [==============================] - 87s 126ms/step - loss: 0.2809 - accuracy: 0.9243 - val_loss: 1.2148 - val_accuracy: 0.6581\n",
      "Epoch 5/15\n",
      "667/667 [==============================] - 76s 107ms/step - loss: 0.2122 - accuracy: 0.9433 - val_loss: 0.9085 - val_accuracy: 0.7306\n",
      "Epoch 6/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.1498 - accuracy: 0.9580 - val_loss: 0.9452 - val_accuracy: 0.7548\n",
      "Epoch 7/15\n",
      "667/667 [==============================] - 64s 93ms/step - loss: 0.1166 - accuracy: 0.9682 - val_loss: 0.8629 - val_accuracy: 0.7786\n",
      "Epoch 8/15\n",
      "667/667 [==============================] - 64s 92ms/step - loss: 0.1081 - accuracy: 0.9706 - val_loss: 0.8248 - val_accuracy: 0.7853\n",
      "Epoch 9/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.0909 - accuracy: 0.9751 - val_loss: 0.8156 - val_accuracy: 0.7933\n",
      "Epoch 10/15\n",
      "667/667 [==============================] - 63s 91ms/step - loss: 0.0777 - accuracy: 0.9796 - val_loss: 0.7647 - val_accuracy: 0.8238\n",
      "Epoch 11/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.0788 - accuracy: 0.9794 - val_loss: 0.7611 - val_accuracy: 0.8178\n",
      "Epoch 12/15\n",
      "667/667 [==============================] - 62s 90ms/step - loss: 0.0602 - accuracy: 0.9848 - val_loss: 0.8232 - val_accuracy: 0.8163\n",
      "Epoch 13/15\n",
      "667/667 [==============================] - 63s 92ms/step - loss: 0.0734 - accuracy: 0.9820 - val_loss: 0.7240 - val_accuracy: 0.8280\n",
      "Epoch 14/15\n",
      "667/667 [==============================] - 61s 88ms/step - loss: 0.0639 - accuracy: 0.9831 - val_loss: 0.8091 - val_accuracy: 0.8145\n",
      "Epoch 15/15\n",
      "667/667 [==============================] - 63s 92ms/step - loss: 0.0532 - accuracy: 0.9887 - val_loss: 0.6909 - val_accuracy: 0.8473\n",
      "테스트 데이터 추론 시작...\n",
      "345/345 [==============================] - 89s 256ms/step\n",
      "추론 완료\n",
      "submission.csv 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# -----------------------\n",
    "# GPU 확인\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"[INFO] {len(gpus)} GPU(s) available: {[gpu.name for gpu in gpus]}\")\n",
    "else:\n",
    "    print(\"[INFO] No GPU available. Training will use CPU.\")\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 15,\n",
    "    'LR': 3e-4,\n",
    "    'BATCH_SIZE': 24,\n",
    "    'SEED': 2025,\n",
    "    'FOLDS': 5\n",
    "}\n",
    "\n",
    "# Seed 고정\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(CFG['SEED'])\n",
    "\n",
    "# -----------------------\n",
    "# 경로 설정\n",
    "ORIGINAL_TRAIN_DIR = \"D:/데이콘 250519 대회/open/train\"        # 원본 원천 데이터셋\n",
    "FILTERED_TRAIN_DIR = \"D:/데이콘 250519 대회/filtered_train\"    # 필터링 결과 저장 폴더\n",
    "TEST_DIR = \"D:/데이콘 250519 대회/open/test\"\n",
    "SAMPLE_SUB = \"D:/데이콘 250519 대회/open/sample_submission.csv\"\n",
    "\n",
    "# -----------------------\n",
    "# YOLOv8 차량 외관 필터링 함수\n",
    "\n",
    "VEHICLE_CLASSES = [2, 5, 7]  # car, bus, truck 클래스 번호\n",
    "\n",
    "yolo_model = YOLO('yolov8n.pt')  # 필요시 yolov8s.pt 등으로 변경 가능\n",
    "\n",
    "def is_full_vehicle(detections, img):\n",
    "    \"\"\"\n",
    "    차량 전체 외관 포함 여부 판단 함수.\n",
    "    트렁크, 보닛 열린 이미지, 내부 이미지 등을 제거하기 위한 조건 강화\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    img_area = h * w\n",
    "\n",
    "    full_vehicle_found = False\n",
    "\n",
    "    for det in detections:\n",
    "        cls = int(det.cls)\n",
    "        if cls not in VEHICLE_CLASSES:\n",
    "            continue\n",
    "\n",
    "        # 박스 좌표 추출\n",
    "        x1, y1, x2, y2 = det.xyxy[0].cpu().numpy()\n",
    "        box_w, box_h = x2 - x1, y2 - y1\n",
    "        area = box_w * box_h\n",
    "        center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "        aspect_ratio = box_w / box_h\n",
    "\n",
    "        # 조건 1: 차량 클래스일 것\n",
    "        # 조건 2: 박스가 이미지 중앙에 위치 (중앙 근처, 중심 좌표 비율 조정)\n",
    "        if not (0.4 * w < center_x < 0.6 * w and 0.4 * h < center_y < 0.6 * h):\n",
    "            continue\n",
    "\n",
    "        # 조건 3: 박스 면적이 이미지 대비 최소 40% 이상 (작은 박스는 제거)\n",
    "        if area / img_area < 0.40:\n",
    "            continue\n",
    "\n",
    "        # 조건 4: 박스의 비율 제한 (너무 좁거나 넓으면 제외)\n",
    "        # 보닛, 트렁크 열린 경우 가로세로 비율 극단적일 수 있음\n",
    "        if aspect_ratio < 0.9 or aspect_ratio > 1.8:\n",
    "            continue\n",
    "\n",
    "        # 조건 5: 보닛이나 트렁크 열린 이미지/내부 이미지는 비율, 위치 조건으로 대부분 걸러짐\n",
    "        # 필요시 추가 조건 작성 가능\n",
    "\n",
    "        # 위 조건 모두 만족 시 전체 차량 외관 포함으로 판단\n",
    "        full_vehicle_found = True\n",
    "        break\n",
    "\n",
    "    return full_vehicle_found\n",
    "\n",
    "# -----------------------\n",
    "# 차량 외관 필터링 수행\n",
    "\n",
    "print(\"차량 외관 이상치 필터링 시작...\")\n",
    "os.makedirs(FILTERED_TRAIN_DIR, exist_ok=True)\n",
    "class_dirs = sorted(os.listdir(ORIGINAL_TRAIN_DIR))\n",
    "\n",
    "filtered_count = 0\n",
    "total_count = 0\n",
    "\n",
    "for cls in tqdm(class_dirs, desc=\"클래스별 필터링\"):\n",
    "    input_dir = os.path.join(ORIGINAL_TRAIN_DIR, cls)\n",
    "    output_dir = os.path.join(FILTERED_TRAIN_DIR, cls)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    image_paths = glob(os.path.join(input_dir, \"*.jpg\"))\n",
    "    for img_path in image_paths:\n",
    "        total_count += 1\n",
    "        img = cv2.imread(img_path)\n",
    "        results = yolo_model(img, verbose=False)[0]\n",
    "\n",
    "        if is_full_vehicle(results.boxes, img):\n",
    "            filename = os.path.basename(img_path)\n",
    "            cv2.imwrite(os.path.join(output_dir, filename), img)\n",
    "            filtered_count += 1\n",
    "\n",
    "print(f\"🔍 전체 이미지 수: {total_count}\")\n",
    "print(f\"✅ 필터링된 차량 외관 이미지 수: {filtered_count}\")\n",
    "print(f\"🧼 이상치 제거 완료. 정제 비율: {filtered_count / total_count:.2%}\")\n",
    "\n",
    "# -----------------------\n",
    "# 학습 데이터 준비\n",
    "\n",
    "label_list = sorted(os.listdir(FILTERED_TRAIN_DIR))\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "id2label = {i: v for v, i in label2id.items()}\n",
    "\n",
    "image_paths = glob(os.path.join(FILTERED_TRAIN_DIR, '*', '*.jpg'))\n",
    "labels = [label2id[os.path.basename(os.path.dirname(p))] for p in image_paths]\n",
    "\n",
    "# -----------------------\n",
    "# 데이터 전처리 함수\n",
    "\n",
    "def load_and_preprocess(img_path):\n",
    "    img = load_img(img_path, target_size=(CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def create_dataset(image_paths, labels=None, is_train=True):\n",
    "    def gen():\n",
    "        for i, path in enumerate(image_paths):\n",
    "            img = load_and_preprocess(path)\n",
    "            if labels is not None:\n",
    "                yield img, labels[i]\n",
    "            else:\n",
    "                yield img\n",
    "\n",
    "    if labels is not None:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=(tf.float32, tf.int32),\n",
    "            output_shapes=((CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3), ())\n",
    "        )\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=tf.float32,\n",
    "            output_shapes=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3)\n",
    "        )\n",
    "\n",
    "    if is_train:\n",
    "        ds = ds.shuffle(1024)\n",
    "    ds = ds.batch(CFG['BATCH_SIZE']).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# -----------------------\n",
    "# 모델 생성\n",
    "\n",
    "def build_model(num_classes):\n",
    "    base = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False,\n",
    "        input_shape=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3),\n",
    "        weights='imagenet',\n",
    "        pooling='avg'\n",
    "    )\n",
    "    x = layers.Dense(num_classes, activation='softmax')(base.output)\n",
    "    model = models.Model(inputs=base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# -----------------------\n",
    "# Stratified K-Fold 학습\n",
    "\n",
    "skf = StratifiedKFold(n_splits=CFG['FOLDS'], shuffle=True, random_state=CFG['SEED'])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n",
    "    print(f\"\\n### Fold {fold+1} 시작 ###\")\n",
    "\n",
    "    train_paths = [image_paths[i] for i in train_idx]\n",
    "    val_paths = [image_paths[i] for i in val_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    train_ds = create_dataset(train_paths, train_labels, is_train=True)\n",
    "    val_ds = create_dataset(val_paths, val_labels, is_train=False)\n",
    "\n",
    "    model = build_model(num_classes=len(label2id))\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(CFG['LR']),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=CFG['EPOCHS'],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "# -----------------------\n",
    "# 테스트 데이터 추론 및 제출 파일 생성\n",
    "\n",
    "test_paths = sorted(glob(os.path.join(TEST_DIR, '*.jpg')))\n",
    "test_ds = create_dataset(test_paths, is_train=False)\n",
    "\n",
    "print(\"테스트 데이터 추론 시작...\")\n",
    "preds = model.predict(test_ds)\n",
    "print(\"추론 완료\")\n",
    "\n",
    "submission = pd.read_csv(SAMPLE_SUB)\n",
    "for idx, class_name in enumerate(label2id.keys()):\n",
    "    submission[class_name] = preds[:, idx]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv 저장 완료\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
