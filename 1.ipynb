{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fecd629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13208\\3107937678.py\", line 11, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=3.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 124\u001b[0m\n\u001b[0;32m    121\u001b[0m skf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mCFG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFOLDS\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mCFG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEED\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    122\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_idx, val_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(skf\u001b[38;5;241m.\u001b[39msplit(image_paths, labels)):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    126\u001b[0m     train_paths \u001b[38;5;241m=\u001b[39m [image_paths[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m train_idx]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\model_selection\\_split.py:404\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    402\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m--> 404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    405\u001b[0m         (\n\u001b[0;32m    406\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    408\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    409\u001b[0m     )\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=3."
     ]
    }
   ],
   "source": [
    "# HiCAR Challenge Pipeline (Updated)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "\n",
    "# Config\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 15,\n",
    "    'LR': 3e-4,\n",
    "    'BATCH_SIZE': 24,\n",
    "    'SEED': 2025,\n",
    "    'FOLDS': 5\n",
    "}\n",
    "\n",
    "# Seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(CFG['SEED'])\n",
    "\n",
    "# Path\n",
    "TRAIN_DIR = \"D:/데이콘 250519 대회/clean_train\"\n",
    "TEST_DIR = \"D:/데이콘 250519 대회/open/test\"\n",
    "SAMPLE_SUB = \"D:/데이콘 250519 대회/open/sample_submission.csv\"\n",
    "\n",
    "# Label Mapping\n",
    "label_list = sorted(os.listdir(TRAIN_DIR))\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "id2label = {i: v for v, i in label2id.items()}\n",
    "\n",
    "# Dataset\n",
    "class HiCarDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.labels is not None:\n",
    "            return img, self.labels[idx]\n",
    "        return img\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Image & Label\n",
    "image_paths = glob(os.path.join(TRAIN_DIR, '*', '*.jpg'))\n",
    "labels = [label2id[os.path.basename(os.path.dirname(p))] for p in image_paths]\n",
    "\n",
    "# Model\n",
    "class HiCarModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = models.efficientnet_b0(pretrained=True)\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Training loop\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    return total_loss / len(loader), acc\n",
    "\n",
    "# Cross-validation\n",
    "skf = StratifiedKFold(n_splits=CFG['FOLDS'], shuffle=True, random_state=CFG['SEED'])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    train_paths = [image_paths[i] for i in train_idx]\n",
    "    val_paths = [image_paths[i] for i in val_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    train_ds = HiCarDataset(train_paths, train_labels, transform)\n",
    "    val_ds = HiCarDataset(val_paths, val_labels, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "    model = HiCarModel(len(label2id)).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CFG['LR'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(CFG['EPOCHS']):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f}\")\n",
    "\n",
    "# Inference\n",
    "model.eval()\n",
    "test_paths = sorted(glob(os.path.join(TEST_DIR, '*.jpg')))\n",
    "test_ds = HiCarDataset(test_paths, transform=transform)\n",
    "test_loader = DataLoader(test_ds, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for imgs in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "        predictions.extend(probs)\n",
    "\n",
    "# Submission\n",
    "submission = pd.read_csv(SAMPLE_SUB)\n",
    "submission[label2id.keys()] = predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e969b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af07266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2f29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 1\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 523s 241ms/step - loss: 2.6151 - accuracy: 0.5248 - val_loss: 4.1993 - val_accuracy: 0.2067\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 147s 126ms/step - loss: 0.7194 - accuracy: 0.8166 - val_loss: 2.7278 - val_accuracy: 0.3585\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 99s 87ms/step - loss: 0.3196 - accuracy: 0.9160 - val_loss: 2.4004 - val_accuracy: 0.4262\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.2041 - accuracy: 0.9457 - val_loss: 2.2646 - val_accuracy: 0.4730\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.1533 - accuracy: 0.9597 - val_loss: 2.0792 - val_accuracy: 0.5023\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.1198 - accuracy: 0.9685 - val_loss: 1.7726 - val_accuracy: 0.5821\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0967 - accuracy: 0.9751 - val_loss: 2.0723 - val_accuracy: 0.5475\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0889 - accuracy: 0.9772 - val_loss: 1.7858 - val_accuracy: 0.5910\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.0760 - accuracy: 0.9805 - val_loss: 1.8156 - val_accuracy: 0.5997\n",
      "Epoch 10/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0697 - accuracy: 0.9813 - val_loss: 1.5716 - val_accuracy: 0.6390\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.0642 - accuracy: 0.9834 - val_loss: 1.4925 - val_accuracy: 0.6448\n",
      "Epoch 12/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.0551 - accuracy: 0.9867 - val_loss: 1.6319 - val_accuracy: 0.6495\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.0514 - accuracy: 0.9863 - val_loss: 1.8704 - val_accuracy: 0.6055\n",
      "Epoch 14/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.0499 - accuracy: 0.9868 - val_loss: 1.4642 - val_accuracy: 0.6703\n",
      "Epoch 15/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.0400 - accuracy: 0.9890 - val_loss: 1.6257 - val_accuracy: 0.6540\n",
      "\n",
      "### Fold 2\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 101s 85ms/step - loss: 2.5741 - accuracy: 0.5377 - val_loss: 4.1205 - val_accuracy: 0.1845\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.7201 - accuracy: 0.8179 - val_loss: 2.7513 - val_accuracy: 0.3503\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.3125 - accuracy: 0.9164 - val_loss: 2.2338 - val_accuracy: 0.4442\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.1970 - accuracy: 0.9502 - val_loss: 2.0922 - val_accuracy: 0.5060\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.1420 - accuracy: 0.9627 - val_loss: 2.0473 - val_accuracy: 0.5017\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.1145 - accuracy: 0.9712 - val_loss: 1.8675 - val_accuracy: 0.5653\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 95s 85ms/step - loss: 0.0977 - accuracy: 0.9741 - val_loss: 1.7520 - val_accuracy: 0.5840\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 95s 85ms/step - loss: 0.0854 - accuracy: 0.9773 - val_loss: 1.8046 - val_accuracy: 0.6027\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.0734 - accuracy: 0.9810 - val_loss: 1.7386 - val_accuracy: 0.6106\n",
      "Epoch 10/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0637 - accuracy: 0.9833 - val_loss: 1.7301 - val_accuracy: 0.6153\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.0560 - accuracy: 0.9856 - val_loss: 1.9505 - val_accuracy: 0.5816\n",
      "Epoch 12/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.0510 - accuracy: 0.9860 - val_loss: 1.8899 - val_accuracy: 0.6148\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0539 - accuracy: 0.9867 - val_loss: 1.7501 - val_accuracy: 0.6298\n",
      "Epoch 14/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0468 - accuracy: 0.9884 - val_loss: 1.8924 - val_accuracy: 0.6174\n",
      "Epoch 15/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0409 - accuracy: 0.9894 - val_loss: 1.7598 - val_accuracy: 0.6353\n",
      "\n",
      "### Fold 3\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 101s 85ms/step - loss: 2.5682 - accuracy: 0.5347 - val_loss: 4.3368 - val_accuracy: 0.1931\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.7229 - accuracy: 0.8143 - val_loss: 2.8300 - val_accuracy: 0.3526\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.3121 - accuracy: 0.9178 - val_loss: 2.4225 - val_accuracy: 0.4313\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.1956 - accuracy: 0.9483 - val_loss: 2.1902 - val_accuracy: 0.4716\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.1468 - accuracy: 0.9621 - val_loss: 1.9782 - val_accuracy: 0.5363\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.1156 - accuracy: 0.9707 - val_loss: 2.0496 - val_accuracy: 0.5401\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.1064 - accuracy: 0.9717 - val_loss: 1.6931 - val_accuracy: 0.5896\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.0878 - accuracy: 0.9778 - val_loss: 1.6386 - val_accuracy: 0.6046\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - 95s 84ms/step - loss: 0.0766 - accuracy: 0.9786 - val_loss: 1.6496 - val_accuracy: 0.6256\n",
      "Epoch 10/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0697 - accuracy: 0.9819 - val_loss: 1.7709 - val_accuracy: 0.6099\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0578 - accuracy: 0.9845 - val_loss: 1.7353 - val_accuracy: 0.6185\n",
      "Epoch 12/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.0510 - accuracy: 0.9860 - val_loss: 1.5522 - val_accuracy: 0.6513\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0517 - accuracy: 0.9856 - val_loss: 1.7777 - val_accuracy: 0.6268\n",
      "Epoch 14/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0447 - accuracy: 0.9877 - val_loss: 1.8502 - val_accuracy: 0.6142\n",
      "Epoch 15/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0461 - accuracy: 0.9879 - val_loss: 1.8127 - val_accuracy: 0.6356\n",
      "\n",
      "### Fold 4\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 102s 86ms/step - loss: 2.6183 - accuracy: 0.5270 - val_loss: 4.3012 - val_accuracy: 0.1963\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.7201 - accuracy: 0.8170 - val_loss: 2.7284 - val_accuracy: 0.3564\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.3045 - accuracy: 0.9197 - val_loss: 2.2180 - val_accuracy: 0.4566\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.1936 - accuracy: 0.9497 - val_loss: 2.0008 - val_accuracy: 0.5143\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.1392 - accuracy: 0.9641 - val_loss: 1.9725 - val_accuracy: 0.5340\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.1154 - accuracy: 0.9691 - val_loss: 1.8718 - val_accuracy: 0.5595\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 97s 85ms/step - loss: 0.0904 - accuracy: 0.9766 - val_loss: 1.9068 - val_accuracy: 0.5837\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.0807 - accuracy: 0.9796 - val_loss: 1.8110 - val_accuracy: 0.6007\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - 97s 85ms/step - loss: 0.0740 - accuracy: 0.9813 - val_loss: 1.7487 - val_accuracy: 0.6098\n",
      "Epoch 10/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.0698 - accuracy: 0.9810 - val_loss: 1.8487 - val_accuracy: 0.5992\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.0608 - accuracy: 0.9842 - val_loss: 1.8224 - val_accuracy: 0.6078\n",
      "Epoch 12/15\n",
      "1105/1105 [==============================] - 97s 85ms/step - loss: 0.0493 - accuracy: 0.9868 - val_loss: 1.6436 - val_accuracy: 0.6300\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.0534 - accuracy: 0.9868 - val_loss: 1.6797 - val_accuracy: 0.6253\n",
      "Epoch 14/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.0522 - accuracy: 0.9863 - val_loss: 1.9163 - val_accuracy: 0.6010\n",
      "Epoch 15/15\n",
      "1105/1105 [==============================] - 97s 85ms/step - loss: 0.0480 - accuracy: 0.9869 - val_loss: 1.7659 - val_accuracy: 0.6335\n",
      "\n",
      "### Fold 5\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 102s 86ms/step - loss: 2.6392 - accuracy: 0.5320 - val_loss: 4.2084 - val_accuracy: 0.1999\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.7189 - accuracy: 0.8168 - val_loss: 2.7985 - val_accuracy: 0.3513\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.3143 - accuracy: 0.9145 - val_loss: 2.3394 - val_accuracy: 0.4391\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.1951 - accuracy: 0.9490 - val_loss: 1.9873 - val_accuracy: 0.5242\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.1479 - accuracy: 0.9604 - val_loss: 1.8491 - val_accuracy: 0.5336\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 97s 85ms/step - loss: 0.1055 - accuracy: 0.9731 - val_loss: 1.8875 - val_accuracy: 0.5609\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 97s 85ms/step - loss: 0.0974 - accuracy: 0.9742 - val_loss: 1.9631 - val_accuracy: 0.5645\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0823 - accuracy: 0.9794 - val_loss: 1.6632 - val_accuracy: 0.6024\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - 97s 85ms/step - loss: 0.0685 - accuracy: 0.9830 - val_loss: 1.5720 - val_accuracy: 0.6335\n",
      "Epoch 10/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0691 - accuracy: 0.9803 - val_loss: 1.7200 - val_accuracy: 0.6160\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0601 - accuracy: 0.9842 - val_loss: 1.6476 - val_accuracy: 0.6433\n",
      "Epoch 12/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0573 - accuracy: 0.9850 - val_loss: 1.5642 - val_accuracy: 0.6555\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0499 - accuracy: 0.9870 - val_loss: 1.6436 - val_accuracy: 0.6478\n",
      "Epoch 14/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0467 - accuracy: 0.9876 - val_loss: 1.7764 - val_accuracy: 0.6378\n",
      "Epoch 15/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.0458 - accuracy: 0.9876 - val_loss: 1.7180 - val_accuracy: 0.6493\n",
      "345/345 [==============================] - 76s 218ms/step\n",
      "Inference 완료\n",
      "submission.csv 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# Config\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 15,\n",
    "    'LR': 3e-4,\n",
    "    'BATCH_SIZE': 24,\n",
    "    'SEED': 2025,\n",
    "    'FOLDS': 5\n",
    "}\n",
    "\n",
    "# Set seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(CFG['SEED'])\n",
    "\n",
    "# Path\n",
    "TRAIN_DIR = \"D:/데이콘 250519 대회/open/train\"\n",
    "TEST_DIR = \"D:/데이콘 250519 대회/open/test\"\n",
    "SAMPLE_SUB = \"D:/데이콘 250519 대회/open/sample_submission.csv\"\n",
    "\n",
    "# Label mapping\n",
    "label_list = sorted(os.listdir(TRAIN_DIR))\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "id2label = {i: v for v, i in label2id.items()}\n",
    "\n",
    "# Load data\n",
    "image_paths = glob(os.path.join(TRAIN_DIR, '*', '*.jpg'))\n",
    "labels = [label2id[os.path.basename(os.path.dirname(p))] for p in image_paths]\n",
    "\n",
    "# Data preprocessing\n",
    "def load_and_preprocess(img_path):\n",
    "    img = load_img(img_path, target_size=(CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# TF Dataset 생성 함수\n",
    "def create_dataset(image_paths, labels=None, is_train=True):\n",
    "    def gen():\n",
    "        for i, path in enumerate(image_paths):\n",
    "            img = load_and_preprocess(path)\n",
    "            if labels is not None:\n",
    "                yield img, labels[i]\n",
    "            else:\n",
    "                yield img\n",
    "\n",
    "    if labels is not None:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=(tf.float32, tf.int32),\n",
    "            output_shapes=((CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3), ())\n",
    "        )\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=tf.float32,\n",
    "            output_shapes=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3)\n",
    "        )\n",
    "\n",
    "    if is_train:\n",
    "        ds = ds.shuffle(1024)\n",
    "    ds = ds.batch(CFG['BATCH_SIZE']).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Model\n",
    "def build_model(num_classes):\n",
    "    base = tf.keras.applications.EfficientNetB0(include_top=False, input_shape=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3), weights='imagenet', pooling='avg')\n",
    "    x = layers.Dense(num_classes, activation='softmax')(base.output)\n",
    "    model = models.Model(inputs=base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Cross-validation training\n",
    "skf = StratifiedKFold(n_splits=CFG['FOLDS'], shuffle=True, random_state=CFG['SEED'])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n",
    "    print(f\"\\n### Fold {fold+1}\")\n",
    "\n",
    "    train_paths = [image_paths[i] for i in train_idx]\n",
    "    val_paths = [image_paths[i] for i in val_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    train_ds = create_dataset(train_paths, train_labels, is_train=True)\n",
    "    val_ds = create_dataset(val_paths, val_labels, is_train=False)\n",
    "\n",
    "    model = build_model(num_classes=len(label2id))\n",
    "    model.compile(optimizer=optimizers.Adam(CFG['LR']),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_ds,\n",
    "              validation_data=val_ds,\n",
    "              epochs=CFG['EPOCHS'],\n",
    "              verbose=1)\n",
    "\n",
    "# Inference\n",
    "test_paths = sorted(glob(os.path.join(TEST_DIR, '*.jpg')))\n",
    "test_ds = create_dataset(test_paths, is_train=False)\n",
    "\n",
    "preds = model.predict(test_ds)\n",
    "print(\"Inference 완료\")\n",
    "\n",
    "# Submission\n",
    "submission = pd.read_csv(SAMPLE_SUB)\n",
    "for idx, class_name in enumerate(label2id.keys()):\n",
    "    submission[class_name] = preds[:, idx]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a0c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f61659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# 원본 경로\n",
    "TRAIN_DIR = \"D:/데이콘 250519 대회/open/train\"\n",
    "FILTERED_TRAIN_DIR = \"D:/데이콘 250519 대회/open/filtered_train\"\n",
    "OTHERS_DIR = \"D:/데이콘 250519 대회/open/others\"\n",
    "\n",
    "os.makedirs(FILTERED_TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(OTHERS_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5094dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_full_car_image(image_path):\n",
    "    \"\"\"\n",
    "    간단한 기준으로 차 외관 전체가 있는지 판별하는 함수 (크기 + 색상 기준)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        w, h = img.size\n",
    "\n",
    "        # 외관 기준: 세로 또는 가로가 너무 작으면 제외\n",
    "        if w < 150 or h < 150:\n",
    "            return False\n",
    "\n",
    "        # 전체적으로 너무 어둡거나 너무 밝은 이미지는 제외 (내부 이미지 등)\n",
    "        img_np = np.array(img.resize((64, 64))) / 255.0\n",
    "        mean_brightness = img_np.mean()\n",
    "\n",
    "        if mean_brightness < 0.2 or mean_brightness > 0.9:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "    except:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c6cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 396/396 [03:13<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "car_classes = sorted(os.listdir(TRAIN_DIR))\n",
    "for class_name in tqdm(car_classes):\n",
    "    class_dir = os.path.join(TRAIN_DIR, class_name)\n",
    "    save_dir = os.path.join(FILTERED_TRAIN_DIR, class_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    image_paths = glob(os.path.join(class_dir, '*.jpg'))\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        if is_full_car_image(img_path):\n",
    "            shutil.copy(img_path, os.path.join(save_dir, os.path.basename(img_path)))\n",
    "        else:\n",
    "            shutil.copy(img_path, os.path.join(OTHERS_DIR, f\"{class_name}_{os.path.basename(img_path)}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Config\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 15,\n",
    "    'LR': 3e-4,\n",
    "    'BATCH_SIZE': 24,\n",
    "    'SEED': 2025,\n",
    "    'FOLDS': 5\n",
    "}\n",
    "\n",
    "# Seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "set_seed(CFG['SEED'])\n",
    "\n",
    "# Label mapping\n",
    "label_list = sorted(os.listdir(FILTERED_TRAIN_DIR))\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "id2label = {i: v for v, i in label2id.items()}\n",
    "\n",
    "# Load filtered data\n",
    "from glob import glob\n",
    "\n",
    "image_paths = glob(os.path.join(FILTERED_TRAIN_DIR, '*', '*.jpg'))\n",
    "labels = [label2id[os.path.basename(os.path.dirname(p))] for p in image_paths]\n",
    "\n",
    "# DataLoader\n",
    "def load_and_preprocess(img_path):\n",
    "    img = load_img(img_path, target_size=(CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def create_dataset(image_paths, labels=None, is_train=True):\n",
    "    def gen():\n",
    "        for i, path in enumerate(image_paths):\n",
    "            img = load_and_preprocess(path)\n",
    "            if labels is not None:\n",
    "                yield img, labels[i]\n",
    "            else:\n",
    "                yield img\n",
    "\n",
    "    if labels is not None:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=(tf.float32, tf.int32),\n",
    "            output_shapes=((CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3), ())\n",
    "        )\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=tf.float32,\n",
    "            output_shapes=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3)\n",
    "        )\n",
    "\n",
    "    if is_train:\n",
    "        ds = ds.shuffle(1024)\n",
    "    ds = ds.batch(CFG['BATCH_SIZE']).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d27ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 1\n",
      "Epoch 1/15\n",
      "1104/1104 [==============================] - 425s 204ms/step - loss: 5.6717 - accuracy: 0.0250 - val_loss: 6.1473 - val_accuracy: 0.0026 - lr: 3.0000e-04\n",
      "Epoch 2/15\n",
      "1104/1104 [==============================] - 173s 150ms/step - loss: 4.3127 - accuracy: 0.1564 - val_loss: 6.7292 - val_accuracy: 0.0104 - lr: 3.0000e-04\n",
      "Epoch 3/15\n",
      "1104/1104 [==============================] - 100s 88ms/step - loss: 2.8119 - accuracy: 0.3653 - val_loss: 7.0519 - val_accuracy: 0.0633 - lr: 3.0000e-04\n",
      "Epoch 4/15\n",
      "1104/1104 [==============================] - 111s 99ms/step - loss: 1.7504 - accuracy: 0.5597 - val_loss: 7.0581 - val_accuracy: 0.1453 - lr: 3.0000e-04\n",
      "Epoch 5/15\n",
      "1104/1104 [==============================] - 98s 87ms/step - loss: 1.1885 - accuracy: 0.6825 - val_loss: 6.0643 - val_accuracy: 0.2151 - lr: 1.5000e-04\n",
      "Epoch 6/15\n",
      "1104/1104 [==============================] - 98s 87ms/step - loss: 0.8607 - accuracy: 0.7660 - val_loss: 5.8893 - val_accuracy: 0.2665 - lr: 1.5000e-04\n",
      "Epoch 7/15\n",
      "1104/1104 [==============================] - 100s 89ms/step - loss: 0.6568 - accuracy: 0.8117 - val_loss: 5.0163 - val_accuracy: 0.3051 - lr: 1.5000e-04\n",
      "Epoch 8/15\n",
      "1104/1104 [==============================] - 103s 91ms/step - loss: 0.5308 - accuracy: 0.8426 - val_loss: 5.1631 - val_accuracy: 0.3198 - lr: 1.5000e-04\n",
      "Epoch 9/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.4162 - accuracy: 0.8764 - val_loss: 4.7781 - val_accuracy: 0.3628 - lr: 1.5000e-04\n",
      "Epoch 10/15\n",
      "1104/1104 [==============================] - 100s 89ms/step - loss: 0.3389 - accuracy: 0.8965 - val_loss: 4.3395 - val_accuracy: 0.4017 - lr: 1.5000e-04\n",
      "Epoch 11/15\n",
      "1104/1104 [==============================] - 98s 87ms/step - loss: 0.2904 - accuracy: 0.9098 - val_loss: 3.8500 - val_accuracy: 0.4441 - lr: 1.5000e-04\n",
      "Epoch 12/15\n",
      "1104/1104 [==============================] - 99s 87ms/step - loss: 0.2617 - accuracy: 0.9190 - val_loss: 3.3360 - val_accuracy: 0.4891 - lr: 1.5000e-04\n",
      "Epoch 13/15\n",
      "1104/1104 [==============================] - 98s 87ms/step - loss: 0.2227 - accuracy: 0.9301 - val_loss: 3.0254 - val_accuracy: 0.5174 - lr: 1.5000e-04\n",
      "Epoch 14/15\n",
      "1104/1104 [==============================] - 98s 87ms/step - loss: 0.1997 - accuracy: 0.9381 - val_loss: 2.7365 - val_accuracy: 0.5426 - lr: 1.5000e-04\n",
      "Epoch 15/15\n",
      "1104/1104 [==============================] - 99s 88ms/step - loss: 0.1797 - accuracy: 0.9448 - val_loss: 2.8461 - val_accuracy: 0.5494 - lr: 1.5000e-04\n",
      "\n",
      "### Fold 2\n",
      "Epoch 1/15\n",
      "1104/1104 [==============================] - 105s 88ms/step - loss: 5.7044 - accuracy: 0.0241 - val_loss: 5.9551 - val_accuracy: 0.0023 - lr: 3.0000e-04\n",
      "Epoch 2/15\n",
      "1104/1104 [==============================] - 99s 87ms/step - loss: 4.2944 - accuracy: 0.1636 - val_loss: 5.7388 - val_accuracy: 0.0296 - lr: 3.0000e-04\n",
      "Epoch 3/15\n",
      "1104/1104 [==============================] - 98s 87ms/step - loss: 2.7065 - accuracy: 0.3874 - val_loss: 5.2210 - val_accuracy: 0.0973 - lr: 3.0000e-04\n",
      "Epoch 4/15\n",
      "1104/1104 [==============================] - 132s 118ms/step - loss: 1.5607 - accuracy: 0.5898 - val_loss: 5.2455 - val_accuracy: 0.1884 - lr: 3.0000e-04\n",
      "Epoch 5/15\n",
      "1104/1104 [==============================] - 224s 196ms/step - loss: 0.9514 - accuracy: 0.7260 - val_loss: 4.9523 - val_accuracy: 0.2320 - lr: 3.0000e-04\n",
      "Epoch 6/15\n",
      "1104/1104 [==============================] - 99s 87ms/step - loss: 0.6673 - accuracy: 0.7952 - val_loss: 4.3713 - val_accuracy: 0.2952 - lr: 3.0000e-04\n",
      "Epoch 7/15\n",
      "1104/1104 [==============================] - 99s 87ms/step - loss: 0.5135 - accuracy: 0.8442 - val_loss: 4.0895 - val_accuracy: 0.3502 - lr: 3.0000e-04\n",
      "Epoch 8/15\n",
      "1104/1104 [==============================] - 99s 88ms/step - loss: 0.4163 - accuracy: 0.8679 - val_loss: 3.7784 - val_accuracy: 0.3890 - lr: 3.0000e-04\n",
      "Epoch 9/15\n",
      "1104/1104 [==============================] - 102s 90ms/step - loss: 0.3319 - accuracy: 0.8927 - val_loss: 3.9410 - val_accuracy: 0.4160 - lr: 3.0000e-04\n",
      "Epoch 10/15\n",
      "1104/1104 [==============================] - 102s 91ms/step - loss: 0.2889 - accuracy: 0.9054 - val_loss: 3.6171 - val_accuracy: 0.4415 - lr: 3.0000e-04\n",
      "Epoch 11/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.2620 - accuracy: 0.9142 - val_loss: 3.9366 - val_accuracy: 0.4249 - lr: 3.0000e-04\n",
      "Epoch 12/15\n",
      "1104/1104 [==============================] - 100s 89ms/step - loss: 0.2326 - accuracy: 0.9247 - val_loss: 2.8752 - val_accuracy: 0.5174 - lr: 3.0000e-04\n",
      "Epoch 13/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.2143 - accuracy: 0.9310 - val_loss: 2.8824 - val_accuracy: 0.5095 - lr: 3.0000e-04\n",
      "Epoch 14/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.2017 - accuracy: 0.9359 - val_loss: 2.8307 - val_accuracy: 0.5225 - lr: 3.0000e-04\n",
      "Epoch 15/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.1711 - accuracy: 0.9457 - val_loss: 2.5854 - val_accuracy: 0.5532 - lr: 3.0000e-04\n",
      "\n",
      "### Fold 3\n",
      "Epoch 1/15\n",
      "1104/1104 [==============================] - 108s 91ms/step - loss: 5.6969 - accuracy: 0.0243 - val_loss: 5.9502 - val_accuracy: 0.0112 - lr: 3.0000e-04\n",
      "Epoch 2/15\n",
      "1104/1104 [==============================] - 101s 90ms/step - loss: 4.2856 - accuracy: 0.1583 - val_loss: 6.1278 - val_accuracy: 0.0225 - lr: 3.0000e-04\n",
      "Epoch 3/15\n",
      "1104/1104 [==============================] - 102s 90ms/step - loss: 2.5915 - accuracy: 0.3925 - val_loss: 6.1370 - val_accuracy: 0.1154 - lr: 3.0000e-04\n",
      "Epoch 4/15\n",
      "1104/1104 [==============================] - 101s 90ms/step - loss: 1.5365 - accuracy: 0.5900 - val_loss: 5.9454 - val_accuracy: 0.1798 - lr: 3.0000e-04\n",
      "Epoch 5/15\n",
      "1104/1104 [==============================] - 102s 90ms/step - loss: 0.9661 - accuracy: 0.7203 - val_loss: 5.3727 - val_accuracy: 0.2520 - lr: 3.0000e-04\n",
      "Epoch 6/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.6647 - accuracy: 0.7981 - val_loss: 5.2797 - val_accuracy: 0.2853 - lr: 3.0000e-04\n",
      "Epoch 7/15\n",
      "1104/1104 [==============================] - 101s 90ms/step - loss: 0.4981 - accuracy: 0.8458 - val_loss: 4.9859 - val_accuracy: 0.3156 - lr: 3.0000e-04\n",
      "Epoch 8/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.3992 - accuracy: 0.8747 - val_loss: 4.5188 - val_accuracy: 0.3627 - lr: 3.0000e-04\n",
      "Epoch 9/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.3421 - accuracy: 0.8910 - val_loss: 4.1235 - val_accuracy: 0.3943 - lr: 3.0000e-04\n",
      "Epoch 10/15\n",
      "1104/1104 [==============================] - 101s 90ms/step - loss: 0.3008 - accuracy: 0.9022 - val_loss: 3.6433 - val_accuracy: 0.4344 - lr: 3.0000e-04\n",
      "Epoch 11/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.2565 - accuracy: 0.9170 - val_loss: 3.8269 - val_accuracy: 0.4316 - lr: 3.0000e-04\n",
      "Epoch 12/15\n",
      "1104/1104 [==============================] - 101s 90ms/step - loss: 0.2303 - accuracy: 0.9262 - val_loss: 3.1064 - val_accuracy: 0.4896 - lr: 3.0000e-04\n",
      "Epoch 13/15\n",
      "1104/1104 [==============================] - 101s 90ms/step - loss: 0.2128 - accuracy: 0.9294 - val_loss: 3.0232 - val_accuracy: 0.5086 - lr: 3.0000e-04\n",
      "Epoch 14/15\n",
      "1104/1104 [==============================] - 101s 90ms/step - loss: 0.1907 - accuracy: 0.9389 - val_loss: 2.8191 - val_accuracy: 0.5397 - lr: 3.0000e-04\n",
      "Epoch 15/15\n",
      "1104/1104 [==============================] - 101s 90ms/step - loss: 0.1819 - accuracy: 0.9427 - val_loss: 2.6045 - val_accuracy: 0.5373 - lr: 3.0000e-04\n",
      "\n",
      "### Fold 4\n",
      "Epoch 1/15\n",
      "1104/1104 [==============================] - 110s 93ms/step - loss: 5.7203 - accuracy: 0.0245 - val_loss: 6.2947 - val_accuracy: 0.0030 - lr: 3.0000e-04\n",
      "Epoch 2/15\n",
      "1104/1104 [==============================] - 102s 91ms/step - loss: 4.2710 - accuracy: 0.1482 - val_loss: 6.8354 - val_accuracy: 0.0175 - lr: 3.0000e-04\n",
      "Epoch 3/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 2.6972 - accuracy: 0.3646 - val_loss: 7.4312 - val_accuracy: 0.0808 - lr: 3.0000e-04\n",
      "Epoch 4/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 1.6408 - accuracy: 0.5661 - val_loss: 6.9062 - val_accuracy: 0.1615 - lr: 3.0000e-04\n",
      "Epoch 5/15\n",
      "1104/1104 [==============================] - 100s 88ms/step - loss: 1.0979 - accuracy: 0.6976 - val_loss: 5.6947 - val_accuracy: 0.2258 - lr: 1.5000e-04\n",
      "Epoch 6/15\n",
      "1104/1104 [==============================] - 102s 90ms/step - loss: 0.8108 - accuracy: 0.7679 - val_loss: 5.2978 - val_accuracy: 0.2539 - lr: 1.5000e-04\n",
      "Epoch 7/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.6242 - accuracy: 0.8150 - val_loss: 4.8225 - val_accuracy: 0.3062 - lr: 1.5000e-04\n",
      "Epoch 8/15\n",
      "1104/1104 [==============================] - 102s 91ms/step - loss: 0.5023 - accuracy: 0.8505 - val_loss: 4.5635 - val_accuracy: 0.3279 - lr: 1.5000e-04\n",
      "Epoch 9/15\n",
      "1104/1104 [==============================] - 102s 90ms/step - loss: 0.4195 - accuracy: 0.8739 - val_loss: 3.9681 - val_accuracy: 0.3820 - lr: 1.5000e-04\n",
      "Epoch 10/15\n",
      "1104/1104 [==============================] - 105s 93ms/step - loss: 0.3493 - accuracy: 0.8933 - val_loss: 3.8550 - val_accuracy: 0.4077 - lr: 1.5000e-04\n",
      "Epoch 11/15\n",
      "1104/1104 [==============================] - 106s 93ms/step - loss: 0.3022 - accuracy: 0.9070 - val_loss: 4.2497 - val_accuracy: 0.3949 - lr: 1.5000e-04\n",
      "Epoch 12/15\n",
      "1104/1104 [==============================] - 103s 91ms/step - loss: 0.2619 - accuracy: 0.9188 - val_loss: 3.9192 - val_accuracy: 0.4136 - lr: 1.5000e-04\n",
      "Epoch 13/15\n",
      "1104/1104 [==============================] - 104s 92ms/step - loss: 0.2274 - accuracy: 0.9298 - val_loss: 3.5410 - val_accuracy: 0.4615 - lr: 1.5000e-04\n",
      "Epoch 14/15\n",
      "1104/1104 [==============================] - 102s 90ms/step - loss: 0.2074 - accuracy: 0.9362 - val_loss: 3.6381 - val_accuracy: 0.4517 - lr: 1.5000e-04\n",
      "Epoch 15/15\n",
      "1104/1104 [==============================] - 99s 88ms/step - loss: 0.1837 - accuracy: 0.9425 - val_loss: 3.3228 - val_accuracy: 0.4752 - lr: 1.5000e-04\n",
      "\n",
      "### Fold 5\n",
      "Epoch 1/15\n",
      "1104/1104 [==============================] - 106s 90ms/step - loss: 5.6889 - accuracy: 0.0259 - val_loss: 5.9695 - val_accuracy: 0.0103 - lr: 3.0000e-04\n",
      "Epoch 2/15\n",
      "1104/1104 [==============================] - 100s 89ms/step - loss: 4.2025 - accuracy: 0.1585 - val_loss: 5.9056 - val_accuracy: 0.0313 - lr: 3.0000e-04\n",
      "Epoch 3/15\n",
      "1104/1104 [==============================] - 100s 89ms/step - loss: 2.6636 - accuracy: 0.3792 - val_loss: 6.2693 - val_accuracy: 0.0953 - lr: 3.0000e-04\n",
      "Epoch 4/15\n",
      "1104/1104 [==============================] - 100s 88ms/step - loss: 1.5295 - accuracy: 0.5950 - val_loss: 5.6904 - val_accuracy: 0.1801 - lr: 3.0000e-04\n",
      "Epoch 5/15\n",
      "1104/1104 [==============================] - 101s 90ms/step - loss: 0.9680 - accuracy: 0.7223 - val_loss: 4.8853 - val_accuracy: 0.2508 - lr: 3.0000e-04\n",
      "Epoch 6/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.6655 - accuracy: 0.8002 - val_loss: 4.2838 - val_accuracy: 0.3087 - lr: 3.0000e-04\n",
      "Epoch 7/15\n",
      "1104/1104 [==============================] - 102s 90ms/step - loss: 0.5072 - accuracy: 0.8429 - val_loss: 4.0941 - val_accuracy: 0.3488 - lr: 3.0000e-04\n",
      "Epoch 8/15\n",
      "1104/1104 [==============================] - 101s 90ms/step - loss: 0.4038 - accuracy: 0.8722 - val_loss: 3.8088 - val_accuracy: 0.3918 - lr: 3.0000e-04\n",
      "Epoch 9/15\n",
      "1104/1104 [==============================] - 102s 90ms/step - loss: 0.3341 - accuracy: 0.8927 - val_loss: 3.3552 - val_accuracy: 0.4519 - lr: 3.0000e-04\n",
      "Epoch 10/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.2921 - accuracy: 0.9061 - val_loss: 3.1975 - val_accuracy: 0.4532 - lr: 3.0000e-04\n",
      "Epoch 11/15\n",
      "1104/1104 [==============================] - 100s 89ms/step - loss: 0.2637 - accuracy: 0.9155 - val_loss: 3.2638 - val_accuracy: 0.4759 - lr: 3.0000e-04\n",
      "Epoch 12/15\n",
      "1104/1104 [==============================] - 101s 89ms/step - loss: 0.2389 - accuracy: 0.9248 - val_loss: 2.7817 - val_accuracy: 0.4963 - lr: 3.0000e-04\n",
      "Epoch 13/15\n",
      "1104/1104 [==============================] - 100s 89ms/step - loss: 0.2150 - accuracy: 0.9302 - val_loss: 2.4587 - val_accuracy: 0.5418 - lr: 3.0000e-04\n",
      "Epoch 14/15\n",
      "1104/1104 [==============================] - 100s 89ms/step - loss: 0.1882 - accuracy: 0.9397 - val_loss: 2.0584 - val_accuracy: 0.6086 - lr: 3.0000e-04\n",
      "Epoch 15/15\n",
      "1104/1104 [==============================] - 100s 89ms/step - loss: 0.1759 - accuracy: 0.9421 - val_loss: 2.2653 - val_accuracy: 0.5839 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "source": [
    "def build_model(num_classes):\n",
    "    base = EfficientNetB0(include_top=False, input_shape=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3), weights='imagenet', pooling='avg')\n",
    "    x = layers.Dense(128, activation='relu')(base.output)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs=base.input, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=CFG['FOLDS'], shuffle=True, random_state=CFG['SEED'])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n",
    "    print(f\"\\n### Fold {fold+1}\")\n",
    "\n",
    "    train_paths = [image_paths[i] for i in train_idx]\n",
    "    val_paths = [image_paths[i] for i in val_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    train_ds = create_dataset(train_paths, train_labels, is_train=True)\n",
    "    val_ds = create_dataset(val_paths, val_labels, is_train=False)\n",
    "\n",
    "    model = build_model(len(label2id))\n",
    "    model.compile(optimizer=optimizers.Adam(CFG['LR']),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_ds,\n",
    "              validation_data=val_ds,\n",
    "              epochs=CFG['EPOCHS'],\n",
    "              callbacks=[\n",
    "                  tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "                  tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37547478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 24s 69ms/step\n",
      "submission2.csv 저장 완료\n"
     ]
    }
   ],
   "source": [
    "TEST_DIR = \"D:/데이콘 250519 대회/open/test\"\n",
    "SAMPLE_SUB = \"D:/데이콘 250519 대회/open/sample_submission.csv\"\n",
    "\n",
    "test_paths = sorted(glob(os.path.join(TEST_DIR, '*.jpg')))\n",
    "test_ds = create_dataset(test_paths, is_train=False)\n",
    "\n",
    "preds = model.predict(test_ds)\n",
    "\n",
    "# Submission\n",
    "submission = pd.read_csv(SAMPLE_SUB)\n",
    "for idx, class_name in enumerate(label2id.keys()):\n",
    "    submission[class_name] = preds[:, idx]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission2.csv 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3014c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dbb4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f79bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c068e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-gvcjf3ps\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: ftfy in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from clip==1.0) (6.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from clip==1.0) (25.0)\n",
      "Requirement already satisfied: regex in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from clip==1.0) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from clip==1.0) (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from clip==1.0) (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from clip==1.0) (0.22.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from torch->clip==1.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from torch->clip==1.0) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from torch->clip==1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from torch->clip==1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from torch->clip==1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from torch->clip==1.0) (2025.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from torchvision->clip==1.0) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from torchvision->clip==1.0) (11.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\tf\\lib\\site-packages (from tqdm->clip==1.0) (0.4.6)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py): started\n",
      "  Building wheel for clip (setup.py): finished with status 'done'\n",
      "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369632 sha256=cbc231f6fd1c4584bd6a0d413fe4fd071960c878b30d2a47de2b4196364cd836\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-n990sk8s\\wheels\\c8\\e4\\e1\\11374c111387672fc2068dfbe0d4b424cb9cdd1b2e184a71b5\n",
      "Successfully built clip\n",
      "Installing collected packages: clip\n",
      "Successfully installed clip-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-req-build-gvcjf3ps'\n",
      "  DEPRECATION: Building 'clip' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'clip'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84516370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 338M/338M [00:30<00:00, 11.5MiB/s]\n",
      "Filtering: 100%|██████████| 396/396 [35:37<00:00,  5.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# clip_filter.py\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import torch\n",
    "import clip\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Config\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMAGE_DIR = \"D:/데이콘 250519 대회/open/train\"\n",
    "CLEAN_DIR = \"D:/데이콘 250519 대회/clean_train\"\n",
    "FILTERED_DIR = \"D:/데이콘 250519 대회/filtered_train\"\n",
    "THRESHOLD = 0.30  # CLIP 유사도 기준값\n",
    "\n",
    "# Load CLIP\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=DEVICE)\n",
    "\n",
    "# Prompt\n",
    "text_inputs = clip.tokenize([\"a car with full exterior view\"]).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "# 폴더 생성\n",
    "for base_dir in [CLEAN_DIR, FILTERED_DIR]:\n",
    "    for label in os.listdir(IMAGE_DIR):\n",
    "        os.makedirs(os.path.join(base_dir, label), exist_ok=True)\n",
    "\n",
    "# 필터링\n",
    "for label in tqdm(os.listdir(IMAGE_DIR), desc=\"Filtering\"):\n",
    "    img_dir = os.path.join(IMAGE_DIR, label)\n",
    "    for img_name in os.listdir(img_dir):\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "\n",
    "        try:\n",
    "            image = preprocess(Image.open(img_path).convert(\"RGB\")).unsqueeze(0).to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                image_features = model.encode_image(image)\n",
    "                image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "                similarity = (image_features @ text_features.T).squeeze().item()\n",
    "\n",
    "            if similarity >= THRESHOLD:\n",
    "                shutil.copy(img_path, os.path.join(CLEAN_DIR, label, img_name))\n",
    "            else:\n",
    "                shutil.copy(img_path, os.path.join(FILTERED_DIR, label, img_name))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {img_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffbc341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 이미지 수: 3\n",
      "Fold 수 (기본값): 5\n",
      "데이터 수(3)가 Fold 수(5)보다 적어 Fold 수를 조정합니다.\n",
      "최종 Fold 수: 3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_splits=3 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 103\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold\n\u001b[0;32m    101\u001b[0m skf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mCFG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFOLDS\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mCFG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEED\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_idx, val_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(skf\u001b[38;5;241m.\u001b[39msplit(image_paths, labels)):\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    106\u001b[0m     train_paths \u001b[38;5;241m=\u001b[39m [image_paths[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m train_idx]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_split.py:411\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    405\u001b[0m         (\n\u001b[0;32m    406\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    408\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    409\u001b[0m     )\n\u001b[1;32m--> 411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_split.py:142\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    140\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    141\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[0;32m    143\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[0;32m    144\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_split.py:838\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 838\u001b[0m     test_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m test_folds \u001b[38;5;241m==\u001b[39m i\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_split.py:800\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    798\u001b[0m min_groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(y_counts)\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m y_counts):\n\u001b[1;32m--> 800\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    801\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_splits=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m cannot be greater than the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    802\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of members in each class.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits)\n\u001b[0;32m    803\u001b[0m     )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m min_groups:\n\u001b[0;32m    805\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m members, which is less than n_splits=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m         \u001b[38;5;241m%\u001b[39m (min_groups, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits),\n\u001b[0;32m    809\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    810\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: n_splits=3 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# Config\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 15,\n",
    "    'LR': 3e-4,\n",
    "    'BATCH_SIZE': 24,\n",
    "    'SEED': 2025,\n",
    "    'FOLDS': 5\n",
    "}\n",
    "\n",
    "# Seed 고정\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(CFG['SEED'])\n",
    "\n",
    "# 경로\n",
    "TRAIN_DIR = \"D:/데이콘 250519 대회/clean_train\"  # 필터링된 clean_train 사용\n",
    "TEST_DIR = \"D:/데이콘 250519 대회/open/test\"\n",
    "SAMPLE_SUB = \"D:/데이콘 250519 대회/open/sample_submission.csv\"\n",
    "\n",
    "# 라벨 매핑\n",
    "label_list = sorted(os.listdir(TRAIN_DIR))\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "id2label = {i: v for v, i in label2id.items()}\n",
    "\n",
    "# 데이터 로드\n",
    "image_paths = glob(os.path.join(TRAIN_DIR, '*', '*.jpg'))\n",
    "labels = [label2id[os.path.basename(os.path.dirname(p))] for p in image_paths]\n",
    "\n",
    "# 데이터 개수 및 Fold 수 출력 및 조정\n",
    "print(f\"총 이미지 수: {len(image_paths)}\")\n",
    "print(f\"Fold 수 (기본값): {CFG['FOLDS']}\")\n",
    "\n",
    "if len(image_paths) < CFG['FOLDS']:\n",
    "    print(f\"데이터 수({len(image_paths)})가 Fold 수({CFG['FOLDS']})보다 적어 Fold 수를 조정합니다.\")\n",
    "    CFG['FOLDS'] = len(image_paths)\n",
    "\n",
    "print(f\"최종 Fold 수: {CFG['FOLDS']}\")\n",
    "\n",
    "# 이미지 전처리\n",
    "def load_and_preprocess(img_path):\n",
    "    img = load_img(img_path, target_size=(CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# TF Dataset 생성\n",
    "def create_dataset(image_paths, labels=None, is_train=True):\n",
    "    def gen():\n",
    "        for i, path in enumerate(image_paths):\n",
    "            img = load_and_preprocess(path)\n",
    "            if labels is not None:\n",
    "                yield img, labels[i]\n",
    "            else:\n",
    "                yield img\n",
    "\n",
    "    if labels is not None:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=(tf.float32, tf.int32),\n",
    "            output_shapes=((CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3), ())\n",
    "        )\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=tf.float32,\n",
    "            output_shapes=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3)\n",
    "        )\n",
    "\n",
    "    if is_train:\n",
    "        ds = ds.shuffle(1024)\n",
    "    ds = ds.batch(CFG['BATCH_SIZE']).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# 모델 정의\n",
    "def build_model(num_classes):\n",
    "    base = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False, input_shape=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3), weights='imagenet', pooling='avg')\n",
    "    x = layers.Dense(num_classes, activation='softmax')(base.output)\n",
    "    model = models.Model(inputs=base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# 교차검증 학습\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=CFG['FOLDS'], shuffle=True, random_state=CFG['SEED'])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n",
    "    print(f\"\\n### Fold {fold+1}\")\n",
    "\n",
    "    train_paths = [image_paths[i] for i in train_idx]\n",
    "    val_paths = [image_paths[i] for i in val_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    train_ds = create_dataset(train_paths, train_labels, is_train=True)\n",
    "    val_ds = create_dataset(val_paths, val_labels, is_train=False)\n",
    "\n",
    "    model = build_model(num_classes=len(label2id))\n",
    "    model.compile(optimizer=optimizers.Adam(CFG['LR']),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_ds,\n",
    "              validation_data=val_ds,\n",
    "              epochs=CFG['EPOCHS'],\n",
    "              verbose=1)\n",
    "\n",
    "# Inference\n",
    "test_paths = sorted(glob(os.path.join(TEST_DIR, '*.jpg')))\n",
    "test_ds = create_dataset(test_paths, is_train=False)\n",
    "preds = model.predict(test_ds)\n",
    "print(\"✅ Inference 완료\")\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.read_csv(SAMPLE_SUB)\n",
    "for idx, class_name in enumerate(label2id.keys()):\n",
    "    submission[class_name] = preds[:, idx]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ submission.csv 저장 완료\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a0486",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Name tf.RaggedTensorSpec has already been registered for class tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models, optimizers\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_img, img_to_array\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\combinations\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute.combinations namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m env \u001b[38;5;66;03m# line: 456\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate \u001b[38;5;66;03m# line: 365\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m in_main_process \u001b[38;5;66;03m# line: 418\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\distribute\\combinations.py:33\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m session\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective_all_reduce_strategy\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\distribute\\collective_all_reduce_strategy.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensorflow_server_pb2\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cross_device_ops \u001b[38;5;28;01mas\u001b[39;00m cross_device_ops_lib\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\distribute\\cross_device_ops.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m device_lib\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute_utils\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\distribute\\cross_device_utils.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callable, List, Optional, Union\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m values \u001b[38;5;28;01mas\u001b[39;00m value_lib\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backprop_util\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\distribute\\values.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m struct_pb2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m packed_distributed_variable \u001b[38;5;28;01mas\u001b[39;00m packed\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m reduce_util\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:205\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_ctx \u001b[38;5;28;01mas\u001b[39;00m autograph_ctx\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m autograph\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:99\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:419\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_service_pb2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils_exp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\util\\structure.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m resource_variable_ops\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mragged\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ragged_tensor\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_logging \u001b[38;5;28;01mas\u001b[39;00m logging\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m internal\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\ragged\\__init__.py:28\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ragged Tensors.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis package defines ops for manipulating ragged tensors (`tf.RaggedTensor`),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mAPI docstring: tensorflow.ragged\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mragged\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ragged_tensor\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_tensor.py:2321\u001b[0m\n\u001b[0;32m   2313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensors\n\u001b[0;32m   2316\u001b[0m \u001b[38;5;66;03m# ===============================================================================\u001b[39;00m\n\u001b[0;32m   2317\u001b[0m \u001b[38;5;66;03m# RaggedTensorSpec\u001b[39;00m\n\u001b[0;32m   2318\u001b[0m \u001b[38;5;66;03m# ===============================================================================\u001b[39;00m\n\u001b[0;32m   2319\u001b[0m \u001b[38;5;129;43m@tf_export\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRaggedTensorSpec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2320\u001b[0m \u001b[38;5;129;43m@type_spec_registry\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf.RaggedTensorSpec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m-> 2321\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43;01mRaggedTensorSpec\u001b[39;49;00m\u001b[43m(\u001b[49m\n\u001b[0;32m   2322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchableTypeSpec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRaggedTensorSpec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2323\u001b[0m \u001b[38;5;250;43m  \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Type specification for a `tf.RaggedTensor`.\"\"\"\u001b[39;49;00m\n\u001b[0;32m   2325\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;18;43m__slots__\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m   2326\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_shape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_dtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_ragged_rank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_row_splits_dtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_flat_values_spec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   2328\u001b[0m \u001b[43m  \u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\type_spec_registry.py:59\u001b[0m, in \u001b[0;36mregister.<locals>.decorator_fn\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m has already been registered with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m     57\u001b[0m                    (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, _TYPE_SPEC_TO_NAME[\u001b[38;5;28mcls\u001b[39m]))\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _NAME_TO_TYPE_SPEC:\n\u001b[1;32m---> 59\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m has already been registered for class \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m     60\u001b[0m                    (name, _NAME_TO_TYPE_SPEC[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m,\n\u001b[0;32m     61\u001b[0m                     _NAME_TO_TYPE_SPEC[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n\u001b[0;32m     62\u001b[0m _TYPE_SPEC_TO_NAME[\u001b[38;5;28mcls\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m     63\u001b[0m _NAME_TO_TYPE_SPEC[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Name tf.RaggedTensorSpec has already been registered for class tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "# Config\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 15,\n",
    "    'LR': 3e-4,\n",
    "    'BATCH_SIZE': 24,\n",
    "    'SEED': 2025,\n",
    "    'FOLDS': 5\n",
    "}\n",
    "\n",
    "# Set seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(CFG['SEED'])\n",
    "\n",
    "# Paths\n",
    "TRAIN_DIR = \"D:/데이콘 250519 대회/open/train\"\n",
    "TEST_DIR = \"D:/데이콘 250519 대회/open/test\"\n",
    "SAMPLE_SUB = \"D:/데이콘 250519 대회/open/sample_submission.csv\"\n",
    "FILTERED_DIR = \"D:/데이콘 250519 대회/open/filtered_train\"\n",
    "\n",
    "os.makedirs(FILTERED_DIR, exist_ok=True)\n",
    "\n",
    "# CLIP filtering\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "prompt_texts = [\"a full car image\", \"only license plate\", \"interior of a car\", \"partial car image\"]\n",
    "text_tokens = clip.tokenize(prompt_texts).to(device)\n",
    "with torch.no_grad():\n",
    "    text_features = clip_model.encode_text(text_tokens)\n",
    "\n",
    "filtered = []\n",
    "\n",
    "for folder in os.listdir(TRAIN_DIR):\n",
    "    cls_dir = os.path.join(TRAIN_DIR, folder)\n",
    "    filtered_cls_dir = os.path.join(FILTERED_DIR, folder)\n",
    "    os.makedirs(filtered_cls_dir, exist_ok=True)\n",
    "\n",
    "    for img_file in os.listdir(cls_dir):\n",
    "        img_path = os.path.join(cls_dir, img_file)\n",
    "        image = clip_preprocess(Image.open(img_path)).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.encode_image(image)\n",
    "            similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "        full_prob = similarity[0][0].item()\n",
    "        if full_prob >= 0.5:\n",
    "            shutil.copy(img_path, os.path.join(filtered_cls_dir, img_file))\n",
    "        else:\n",
    "            filtered.append(img_path)\n",
    "\n",
    "print(f\"Filtered out {len(filtered)} images.\")\n",
    "\n",
    "# Label mapping\n",
    "label_list = sorted(os.listdir(FILTERED_DIR))\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "id2label = {i: v for v, i in label2id.items()}\n",
    "\n",
    "# Load data\n",
    "image_paths = glob(os.path.join(FILTERED_DIR, '*', '*.jpg'))\n",
    "labels = [label2id[os.path.basename(os.path.dirname(p))] for p in image_paths]\n",
    "\n",
    "# Load & preprocess\n",
    "def load_and_preprocess(img_path):\n",
    "    img = load_img(img_path, target_size=(CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# TF Dataset 생성\n",
    "def create_dataset(image_paths, labels=None, is_train=True):\n",
    "    def gen():\n",
    "        for i, path in enumerate(image_paths):\n",
    "            img = load_and_preprocess(path)\n",
    "            if labels is not None:\n",
    "                yield img, labels[i]\n",
    "            else:\n",
    "                yield img\n",
    "\n",
    "    if labels is not None:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=(tf.float32, tf.int32),\n",
    "            output_shapes=((CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3), ())\n",
    "        )\n",
    "        if is_train:\n",
    "            ds = ds.shuffle(1024)\n",
    "        ds = ds.map(augment_image)\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=tf.float32,\n",
    "            output_shapes=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3)\n",
    "        )\n",
    "    ds = ds.batch(CFG['BATCH_SIZE']).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Data augmentation\n",
    "def augment_image(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    return image, label\n",
    "\n",
    "# Model\n",
    "def build_model(num_classes):\n",
    "    base = tf.keras.applications.EfficientNetB0(include_top=False,\n",
    "                                                input_shape=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3),\n",
    "                                                weights='imagenet',\n",
    "                                                pooling='avg')\n",
    "    x = layers.Dropout(0.3)(base.output)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs=base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Cross-validation\n",
    "skf = StratifiedKFold(n_splits=CFG['FOLDS'], shuffle=True, random_state=CFG['SEED'])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n",
    "    print(f\"\\n### Fold {fold+1}\")\n",
    "\n",
    "    train_paths = [image_paths[i] for i in train_idx]\n",
    "    val_paths = [image_paths[i] for i in val_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    train_ds = create_dataset(train_paths, train_labels, is_train=True)\n",
    "    val_ds = create_dataset(val_paths, val_labels, is_train=False)\n",
    "\n",
    "    model = build_model(num_classes=len(label2id))\n",
    "    model.compile(optimizer=optimizers.Adam(CFG['LR']),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "    ]\n",
    "\n",
    "    model.fit(train_ds,\n",
    "              validation_data=val_ds,\n",
    "              epochs=CFG['EPOCHS'],\n",
    "              callbacks=callbacks,\n",
    "              verbose=1)\n",
    "\n",
    "# Inference\n",
    "test_paths = sorted(glob(os.path.join(TEST_DIR, '*.jpg')))\n",
    "test_ds = create_dataset(test_paths, is_train=False)\n",
    "\n",
    "preds = model.predict(test_ds)\n",
    "print(\"Inference 완료\")\n",
    "\n",
    "# Submission\n",
    "submission = pd.read_csv(SAMPLE_SUB)\n",
    "for idx, class_name in enumerate(label2id.keys()):\n",
    "    submission[class_name] = preds[:, idx]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission4.csv 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opt_einsum\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Installing collected packages: opt_einsum\n",
      "Successfully installed opt_einsum-3.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.19.0 requires flatbuffers>=24.3.25, which is not installed.\n",
      "tensorflow 2.19.0 requires google-pasta>=0.1.1, which is not installed.\n",
      "tensorflow 2.19.0 requires grpcio<2.0,>=1.24.3, which is not installed.\n",
      "tensorflow 2.19.0 requires h5py>=3.11.0, which is not installed.\n",
      "tensorflow 2.19.0 requires keras>=3.5.0, which is not installed.\n",
      "tensorflow 2.19.0 requires libclang>=13.0.0, which is not installed.\n",
      "tensorflow 2.19.0 requires tensorboard~=2.19.0, which is not installed.\n",
      "tensorflow 2.19.0 requires tensorflow-io-gcs-filesystem>=0.23.1; python_version < \"3.12\", which is not installed.\n",
      "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install opt_einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ea8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100830ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca56ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98900fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5c8948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 1\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 345s 91ms/step - loss: 2.8977 - accuracy: 0.4722 - val_loss: 4.5811 - val_accuracy: 0.1734 - lr: 3.0000e-04\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.8868 - accuracy: 0.7816 - val_loss: 2.9406 - val_accuracy: 0.3300 - lr: 3.0000e-04\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 99s 87ms/step - loss: 0.3926 - accuracy: 0.8966 - val_loss: 2.3576 - val_accuracy: 0.4244 - lr: 3.0000e-04\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.2459 - accuracy: 0.9370 - val_loss: 2.3779 - val_accuracy: 0.4510 - lr: 3.0000e-04\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 98s 87ms/step - loss: 0.1810 - accuracy: 0.9514 - val_loss: 2.0148 - val_accuracy: 0.5199 - lr: 3.0000e-04\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 98s 87ms/step - loss: 0.1373 - accuracy: 0.9642 - val_loss: 2.0262 - val_accuracy: 0.5400 - lr: 3.0000e-04\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 98s 87ms/step - loss: 0.1205 - accuracy: 0.9674 - val_loss: 1.9057 - val_accuracy: 0.5673 - lr: 3.0000e-04\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 99s 88ms/step - loss: 0.1051 - accuracy: 0.9730 - val_loss: 1.8064 - val_accuracy: 0.5594 - lr: 3.0000e-04\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.0896 - accuracy: 0.9760 - val_loss: 1.7386 - val_accuracy: 0.5726 - lr: 3.0000e-04\n",
      "Epoch 10/15\n",
      "1105/1105 [==============================] - 99s 87ms/step - loss: 0.0776 - accuracy: 0.9788 - val_loss: 1.5447 - val_accuracy: 0.6362 - lr: 3.0000e-04\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 99s 88ms/step - loss: 0.0693 - accuracy: 0.9815 - val_loss: 1.7908 - val_accuracy: 0.5951 - lr: 3.0000e-04\n",
      "Epoch 12/15\n",
      "1104/1105 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9816\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "1105/1105 [==============================] - 100s 89ms/step - loss: 0.0689 - accuracy: 0.9816 - val_loss: 1.7033 - val_accuracy: 0.6304 - lr: 3.0000e-04\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.0459 - accuracy: 0.9879 - val_loss: 1.2032 - val_accuracy: 0.7197 - lr: 1.5000e-04\n",
      "Epoch 14/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.0323 - accuracy: 0.9915 - val_loss: 1.1374 - val_accuracy: 0.7257 - lr: 1.5000e-04\n",
      "Epoch 15/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.0316 - accuracy: 0.9918 - val_loss: 1.2118 - val_accuracy: 0.7185 - lr: 1.5000e-04\n",
      "\n",
      "### Fold 2\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 107s 90ms/step - loss: 2.8539 - accuracy: 0.4851 - val_loss: 4.4181 - val_accuracy: 0.1634 - lr: 3.0000e-04\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.8663 - accuracy: 0.7863 - val_loss: 2.8192 - val_accuracy: 0.3342 - lr: 3.0000e-04\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.3827 - accuracy: 0.8994 - val_loss: 2.3259 - val_accuracy: 0.4366 - lr: 3.0000e-04\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.2397 - accuracy: 0.9377 - val_loss: 2.1260 - val_accuracy: 0.4709 - lr: 3.0000e-04\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.1719 - accuracy: 0.9550 - val_loss: 2.2263 - val_accuracy: 0.4796 - lr: 3.0000e-04\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 103s 91ms/step - loss: 0.1391 - accuracy: 0.9648 - val_loss: 1.9485 - val_accuracy: 0.5385 - lr: 3.0000e-04\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 100s 89ms/step - loss: 0.1191 - accuracy: 0.9693 - val_loss: 1.7531 - val_accuracy: 0.5656 - lr: 3.0000e-04\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.1044 - accuracy: 0.9724 - val_loss: 1.8903 - val_accuracy: 0.5637 - lr: 3.0000e-04\n",
      "Epoch 9/15\n",
      "1104/1105 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9761\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "1105/1105 [==============================] - 99s 88ms/step - loss: 0.0897 - accuracy: 0.9761 - val_loss: 1.8039 - val_accuracy: 0.5938 - lr: 3.0000e-04\n",
      "Epoch 10/15\n",
      "1105/1105 [==============================] - 99s 87ms/step - loss: 0.0643 - accuracy: 0.9832 - val_loss: 1.3046 - val_accuracy: 0.6765 - lr: 1.5000e-04\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.0451 - accuracy: 0.9888 - val_loss: 1.4355 - val_accuracy: 0.6619 - lr: 1.5000e-04\n",
      "Epoch 12/15\n",
      "1105/1105 [==============================] - 99s 88ms/step - loss: 0.0387 - accuracy: 0.9900 - val_loss: 1.2804 - val_accuracy: 0.6854 - lr: 1.5000e-04\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 101s 90ms/step - loss: 0.0355 - accuracy: 0.9916 - val_loss: 1.3545 - val_accuracy: 0.6749 - lr: 1.5000e-04\n",
      "Epoch 14/15\n",
      "1104/1105 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9908\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "1105/1105 [==============================] - 103s 91ms/step - loss: 0.0362 - accuracy: 0.9908 - val_loss: 1.3683 - val_accuracy: 0.6886 - lr: 1.5000e-04\n",
      "Epoch 15/15\n",
      "1105/1105 [==============================] - 101s 90ms/step - loss: 0.0322 - accuracy: 0.9918 - val_loss: 1.0710 - val_accuracy: 0.7375 - lr: 7.5000e-05\n",
      "\n",
      "### Fold 3\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 117s 99ms/step - loss: 2.8542 - accuracy: 0.4836 - val_loss: 4.5651 - val_accuracy: 0.1631 - lr: 3.0000e-04\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 101s 90ms/step - loss: 0.8716 - accuracy: 0.7804 - val_loss: 2.9889 - val_accuracy: 0.2994 - lr: 3.0000e-04\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.3897 - accuracy: 0.8963 - val_loss: 2.3962 - val_accuracy: 0.4145 - lr: 3.0000e-04\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 102s 90ms/step - loss: 0.2438 - accuracy: 0.9361 - val_loss: 2.2620 - val_accuracy: 0.4590 - lr: 3.0000e-04\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.1816 - accuracy: 0.9521 - val_loss: 2.0337 - val_accuracy: 0.5195 - lr: 3.0000e-04\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 113s 100ms/step - loss: 0.1467 - accuracy: 0.9609 - val_loss: 1.8830 - val_accuracy: 0.5517 - lr: 3.0000e-04\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 111s 98ms/step - loss: 0.1243 - accuracy: 0.9668 - val_loss: 1.6967 - val_accuracy: 0.5835 - lr: 3.0000e-04\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 102s 90ms/step - loss: 0.1012 - accuracy: 0.9735 - val_loss: 1.8382 - val_accuracy: 0.5776 - lr: 3.0000e-04\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9755\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "1105/1105 [==============================] - 112s 99ms/step - loss: 0.0879 - accuracy: 0.9755 - val_loss: 1.7582 - val_accuracy: 0.6010 - lr: 3.0000e-04\n",
      "Epoch 10/15\n",
      "1105/1105 [==============================] - 164s 146ms/step - loss: 0.0649 - accuracy: 0.9829 - val_loss: 1.2739 - val_accuracy: 0.6928 - lr: 1.5000e-04\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 102s 90ms/step - loss: 0.0434 - accuracy: 0.9891 - val_loss: 1.1500 - val_accuracy: 0.7098 - lr: 1.5000e-04\n",
      "Epoch 12/15\n",
      "1105/1105 [==============================] - 108s 95ms/step - loss: 0.0401 - accuracy: 0.9900 - val_loss: 1.1201 - val_accuracy: 0.7115 - lr: 1.5000e-04\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 1.3233 - val_accuracy: 0.6710 - lr: 1.5000e-04\n",
      "Epoch 14/15\n",
      "1104/1105 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9914\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.0336 - accuracy: 0.9914 - val_loss: 1.3479 - val_accuracy: 0.6771 - lr: 1.5000e-04\n",
      "Epoch 15/15\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.0319 - accuracy: 0.9924 - val_loss: 1.0525 - val_accuracy: 0.7328 - lr: 7.5000e-05\n",
      "\n",
      "### Fold 4\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 108s 91ms/step - loss: 2.9100 - accuracy: 0.4695 - val_loss: 4.5862 - val_accuracy: 0.1672 - lr: 3.0000e-04\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.8809 - accuracy: 0.7793 - val_loss: 2.8563 - val_accuracy: 0.3160 - lr: 3.0000e-04\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.3913 - accuracy: 0.8959 - val_loss: 2.4038 - val_accuracy: 0.4109 - lr: 3.0000e-04\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.2457 - accuracy: 0.9357 - val_loss: 2.2532 - val_accuracy: 0.4590 - lr: 3.0000e-04\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 98s 86ms/step - loss: 0.1750 - accuracy: 0.9536 - val_loss: 2.0433 - val_accuracy: 0.5188 - lr: 3.0000e-04\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 99s 87ms/step - loss: 0.1409 - accuracy: 0.9628 - val_loss: 1.9668 - val_accuracy: 0.5473 - lr: 3.0000e-04\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 99s 87ms/step - loss: 0.1087 - accuracy: 0.9704 - val_loss: 1.9439 - val_accuracy: 0.5648 - lr: 3.0000e-04\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 98s 87ms/step - loss: 0.1057 - accuracy: 0.9711 - val_loss: 1.8391 - val_accuracy: 0.5841 - lr: 3.0000e-04\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - 98s 87ms/step - loss: 0.0971 - accuracy: 0.9735 - val_loss: 1.8776 - val_accuracy: 0.5678 - lr: 3.0000e-04\n",
      "Epoch 10/15\n",
      "1104/1105 [============================>.] - ETA: 0s - loss: 0.0838 - accuracy: 0.9774\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.0837 - accuracy: 0.9774 - val_loss: 1.9561 - val_accuracy: 0.5849 - lr: 3.0000e-04\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 98s 86ms/step - loss: 0.0605 - accuracy: 0.9846 - val_loss: 1.3667 - val_accuracy: 0.6849 - lr: 1.5000e-04\n",
      "Epoch 12/15\n",
      "1105/1105 [==============================] - 99s 87ms/step - loss: 0.0405 - accuracy: 0.9905 - val_loss: 1.3284 - val_accuracy: 0.6873 - lr: 1.5000e-04\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 105s 93ms/step - loss: 0.0391 - accuracy: 0.9904 - val_loss: 1.1983 - val_accuracy: 0.7154 - lr: 1.5000e-04\n",
      "Epoch 14/15\n",
      "1105/1105 [==============================] - 102s 90ms/step - loss: 0.0335 - accuracy: 0.9915 - val_loss: 1.2957 - val_accuracy: 0.6917 - lr: 1.5000e-04\n",
      "Epoch 15/15\n",
      "1104/1105 [============================>.] - ETA: 0s - loss: 0.0325 - accuracy: 0.9924\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.0324 - accuracy: 0.9924 - val_loss: 1.4709 - val_accuracy: 0.6762 - lr: 1.5000e-04\n",
      "\n",
      "### Fold 5\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 105s 88ms/step - loss: 2.9279 - accuracy: 0.4747 - val_loss: 4.4970 - val_accuracy: 0.1640 - lr: 3.0000e-04\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 98s 86ms/step - loss: 0.8908 - accuracy: 0.7737 - val_loss: 3.2002 - val_accuracy: 0.2828 - lr: 3.0000e-04\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 98s 86ms/step - loss: 0.3965 - accuracy: 0.8968 - val_loss: 2.6689 - val_accuracy: 0.3798 - lr: 3.0000e-04\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 99s 87ms/step - loss: 0.2420 - accuracy: 0.9370 - val_loss: 2.1661 - val_accuracy: 0.4805 - lr: 3.0000e-04\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 98s 86ms/step - loss: 0.1905 - accuracy: 0.9487 - val_loss: 2.1172 - val_accuracy: 0.5070 - lr: 3.0000e-04\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.1373 - accuracy: 0.9628 - val_loss: 1.8959 - val_accuracy: 0.5496 - lr: 3.0000e-04\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 97s 86ms/step - loss: 0.1189 - accuracy: 0.9681 - val_loss: 1.7554 - val_accuracy: 0.5885 - lr: 3.0000e-04\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 99s 88ms/step - loss: 0.1024 - accuracy: 0.9744 - val_loss: 1.8931 - val_accuracy: 0.5619 - lr: 3.0000e-04\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - 98s 87ms/step - loss: 0.0929 - accuracy: 0.9745 - val_loss: 1.7258 - val_accuracy: 0.5920 - lr: 3.0000e-04\n",
      "Epoch 10/15\n",
      "1105/1105 [==============================] - 98s 86ms/step - loss: 0.0790 - accuracy: 0.9793 - val_loss: 1.7858 - val_accuracy: 0.5933 - lr: 3.0000e-04\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 98s 87ms/step - loss: 0.0758 - accuracy: 0.9805 - val_loss: 1.6456 - val_accuracy: 0.6253 - lr: 3.0000e-04\n",
      "Epoch 12/15\n",
      "1105/1105 [==============================] - 99s 88ms/step - loss: 0.0638 - accuracy: 0.9832 - val_loss: 1.5754 - val_accuracy: 0.6437 - lr: 3.0000e-04\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 99s 87ms/step - loss: 0.0652 - accuracy: 0.9834 - val_loss: 1.5062 - val_accuracy: 0.6594 - lr: 3.0000e-04\n",
      "Epoch 14/15\n",
      "1105/1105 [==============================] - 98s 86ms/step - loss: 0.0559 - accuracy: 0.9844 - val_loss: 1.6926 - val_accuracy: 0.6332 - lr: 3.0000e-04\n",
      "Epoch 15/15\n",
      "1104/1105 [============================>.] - ETA: 0s - loss: 0.0560 - accuracy: 0.9843\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "1105/1105 [==============================] - 98s 87ms/step - loss: 0.0562 - accuracy: 0.9843 - val_loss: 1.6884 - val_accuracy: 0.6398 - lr: 3.0000e-04\n",
      "345/345 [==============================] - 87s 249ms/step\n",
      "Inference 완료\n",
      "submission.csv 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# Config\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 15,\n",
    "    'LR': 3e-4,\n",
    "    'BATCH_SIZE': 24,\n",
    "    'SEED': 2025,\n",
    "    'FOLDS': 5\n",
    "}\n",
    "\n",
    "# Set seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(CFG['SEED'])\n",
    "\n",
    "# Paths\n",
    "TRAIN_DIR = \"D:/데이콘 250519 대회/open/train\"\n",
    "TEST_DIR = \"D:/데이콘 250519 대회/open/test\"\n",
    "SAMPLE_SUB = \"D:/데이콘 250519 대회/open/sample_submission.csv\"\n",
    "\n",
    "# Label mapping\n",
    "label_list = sorted(os.listdir(TRAIN_DIR))\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "id2label = {i: v for v, i in label2id.items()}\n",
    "\n",
    "# Load image paths and labels\n",
    "image_paths = glob(os.path.join(TRAIN_DIR, '*', '*.jpg'))\n",
    "labels = [label2id[os.path.basename(os.path.dirname(p))] for p in image_paths]\n",
    "\n",
    "# Load & preprocess\n",
    "def load_and_preprocess(img_path):\n",
    "    img = load_img(img_path, target_size=(CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# Data augmentation\n",
    "def augment_image(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    return image, label\n",
    "\n",
    "# TF Dataset 생성\n",
    "def create_dataset(image_paths, labels=None, is_train=True):\n",
    "    def gen():\n",
    "        for i, path in enumerate(image_paths):\n",
    "            img = load_and_preprocess(path)\n",
    "            if labels is not None:\n",
    "                yield img, labels[i]\n",
    "            else:\n",
    "                yield img\n",
    "\n",
    "    if labels is not None:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=(tf.float32, tf.int32),\n",
    "            output_shapes=((CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3), ())\n",
    "        )\n",
    "        if is_train:\n",
    "            ds = ds.shuffle(1024)\n",
    "        ds = ds.map(augment_image)\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=tf.float32,\n",
    "            output_shapes=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3)\n",
    "        )\n",
    "    ds = ds.batch(CFG['BATCH_SIZE']).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Model\n",
    "def build_model(num_classes):\n",
    "    base = tf.keras.applications.EfficientNetB0(include_top=False,\n",
    "                                                input_shape=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3),\n",
    "                                                weights='imagenet',\n",
    "                                                pooling='avg')\n",
    "    x = layers.Dropout(0.3)(base.output)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs=base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Cross-validation training\n",
    "skf = StratifiedKFold(n_splits=CFG['FOLDS'], shuffle=True, random_state=CFG['SEED'])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n",
    "    print(f\"\\n### Fold {fold+1}\")\n",
    "\n",
    "    train_paths = [image_paths[i] for i in train_idx]\n",
    "    val_paths = [image_paths[i] for i in val_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    train_ds = create_dataset(train_paths, train_labels, is_train=True)\n",
    "    val_ds = create_dataset(val_paths, val_labels, is_train=False)\n",
    "\n",
    "    model = build_model(num_classes=len(label2id))\n",
    "    model.compile(optimizer=optimizers.Adam(CFG['LR']),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "    ]\n",
    "\n",
    "    model.fit(train_ds,\n",
    "              validation_data=val_ds,\n",
    "              epochs=CFG['EPOCHS'],\n",
    "              callbacks=callbacks,\n",
    "              verbose=1)\n",
    "\n",
    "# Inference\n",
    "test_paths = sorted(glob(os.path.join(TEST_DIR, '*.jpg')))\n",
    "test_ds = create_dataset(test_paths, is_train=False)\n",
    "\n",
    "preds = model.predict(test_ds)\n",
    "print(\"Inference 완료\")\n",
    "\n",
    "# Submission\n",
    "submission = pd.read_csv(SAMPLE_SUB)\n",
    "for idx, class_name in enumerate(label2id.keys()):\n",
    "    submission[class_name] = preds[:, idx]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv 저장 완료\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
