{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58385d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# Config\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 15,\n",
    "    'LR': 3e-4,\n",
    "    'BATCH_SIZE': 24,\n",
    "    'SEED': 2025,\n",
    "    'FOLDS': 5\n",
    "}\n",
    "\n",
    "# Seed 고정\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(CFG['SEED'])\n",
    "\n",
    "# 데이터 경로\n",
    "TRAIN_DIR = \"D:/데이콘 250519 대회/open/train\"\n",
    "TEST_DIR = \"D:/데이콘 250519 대회/open/test\"\n",
    "SAMPLE_SUB = \"D:/데이콘 250519 대회/open/sample_submission.csv\"\n",
    "\n",
    "# 라벨 매핑\n",
    "label_list = sorted(os.listdir(TRAIN_DIR))\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "id2label = {i: v for v, i in label2id.items()}\n",
    "\n",
    "# 이미지 및 라벨 로딩\n",
    "image_paths = glob(os.path.join(TRAIN_DIR, '*', '*.jpg'))\n",
    "labels = [label2id[os.path.basename(os.path.dirname(p))] for p in image_paths]\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "def load_and_preprocess(img_path):\n",
    "    img = load_img(img_path, target_size=(CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# TF Dataset 생성\n",
    "def create_dataset(image_paths, labels=None, is_train=True):\n",
    "    def gen():\n",
    "        for i, path in enumerate(image_paths):\n",
    "            img = load_and_preprocess(path)\n",
    "            if labels is not None:\n",
    "                yield img, labels[i]\n",
    "            else:\n",
    "                yield img\n",
    "\n",
    "    if labels is not None:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=(tf.float32, tf.int32),\n",
    "            output_shapes=((CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3), ())\n",
    "        )\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_types=tf.float32,\n",
    "            output_shapes=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3)\n",
    "        )\n",
    "\n",
    "    if is_train:\n",
    "        ds = ds.shuffle(1024)\n",
    "    ds = ds.batch(CFG['BATCH_SIZE']).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e994a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 1\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 108s 90ms/step - loss: 5.4202 - accuracy: 0.0837 - val_loss: 6.8076 - val_accuracy: 0.0115\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 103s 91ms/step - loss: 2.9113 - accuracy: 0.4162 - val_loss: 6.5617 - val_accuracy: 0.1017\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 103s 91ms/step - loss: 1.0476 - accuracy: 0.7344 - val_loss: 5.6587 - val_accuracy: 0.1886\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.5447 - accuracy: 0.8506 - val_loss: 5.1726 - val_accuracy: 0.2488\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 99s 88ms/step - loss: 0.3588 - accuracy: 0.8997 - val_loss: 4.9013 - val_accuracy: 0.2835\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.2624 - accuracy: 0.9252 - val_loss: 4.3940 - val_accuracy: 0.3378\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 100s 88ms/step - loss: 0.2236 - accuracy: 0.9327 - val_loss: 4.2849 - val_accuracy: 0.3636\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.1742 - accuracy: 0.9479 - val_loss: 4.2703 - val_accuracy: 0.3840\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - 102s 90ms/step - loss: 0.1489 - accuracy: 0.9570 - val_loss: 3.7879 - val_accuracy: 0.4068\n",
      "Epoch 10/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.1435 - accuracy: 0.9592 - val_loss: 3.7618 - val_accuracy: 0.4137\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 102s 90ms/step - loss: 0.1252 - accuracy: 0.9620 - val_loss: 3.2825 - val_accuracy: 0.4573\n",
      "Epoch 12/15\n",
      "1105/1105 [==============================] - 102s 90ms/step - loss: 0.1120 - accuracy: 0.9677 - val_loss: 3.4655 - val_accuracy: 0.4617\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.1078 - accuracy: 0.9678 - val_loss: 3.4576 - val_accuracy: 0.4664\n",
      "Epoch 14/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.1033 - accuracy: 0.9702 - val_loss: 3.9977 - val_accuracy: 0.4443\n",
      "Epoch 15/15\n",
      "1105/1105 [==============================] - 101s 89ms/step - loss: 0.0925 - accuracy: 0.9741 - val_loss: 3.4417 - val_accuracy: 0.4833\n",
      "\n",
      "### Fold 2\n",
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 105s 88ms/step - loss: 5.4332 - accuracy: 0.0838 - val_loss: 6.3564 - val_accuracy: 0.0118\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 98s 87ms/step - loss: 2.9572 - accuracy: 0.4036 - val_loss: 6.2458 - val_accuracy: 0.1085\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 98s 87ms/step - loss: 1.0794 - accuracy: 0.7265 - val_loss: 5.8316 - val_accuracy: 0.1801\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 96s 85ms/step - loss: 0.5350 - accuracy: 0.8537 - val_loss: 4.9934 - val_accuracy: 0.2539\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 144s 128ms/step - loss: 0.3516 - accuracy: 0.9019 - val_loss: 4.2120 - val_accuracy: 0.3114\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 121s 106ms/step - loss: 0.2564 - accuracy: 0.9283 - val_loss: 4.2380 - val_accuracy: 0.3392\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 135s 119ms/step - loss: 0.2129 - accuracy: 0.9391 - val_loss: 3.9614 - val_accuracy: 0.3826\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 159s 140ms/step - loss: 0.1775 - accuracy: 0.9470 - val_loss: 4.2643 - val_accuracy: 0.3923\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - 421s 370ms/step - loss: 0.1479 - accuracy: 0.9575 - val_loss: 3.6558 - val_accuracy: 0.4252\n",
      "Epoch 10/15\n",
      " 460/1105 [===========>..................] - ETA: 4:21 - loss: 0.1216 - accuracy: 0.9624"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# EfficientNet 기반 모델 생성\n",
    "def build_model(num_classes):\n",
    "    base = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False,\n",
    "        input_shape=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3),\n",
    "        weights='imagenet',\n",
    "        pooling='avg'\n",
    "    )\n",
    "    base.trainable = True  # 모든 레이어 학습 (GPU 성능 활용)\n",
    "\n",
    "    x = layers.Dense(256, activation='relu')(base.output)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=base.input, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Stratified K-Fold 설정\n",
    "skf = StratifiedKFold(n_splits=CFG['FOLDS'], shuffle=True, random_state=CFG['SEED'])\n",
    "\n",
    "best_val_acc = 0\n",
    "best_model_path = \"best_model_weights.h5\"\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n",
    "    print(f\"\\n### Fold {fold+1}\")\n",
    "\n",
    "    train_paths = [image_paths[i] for i in train_idx]\n",
    "    val_paths = [image_paths[i] for i in val_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    train_ds = create_dataset(train_paths, train_labels, is_train=True)\n",
    "    val_ds = create_dataset(val_paths, val_labels, is_train=False)\n",
    "\n",
    "    model = build_model(num_classes=len(label2id))\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(CFG['LR']),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            f\"fold{fold+1}_best_weights.h5\", \n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,  # JSON 오류 방지\n",
    "            monitor=\"val_accuracy\", \n",
    "            mode=\"max\"\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_accuracy\", patience=3, restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=CFG['EPOCHS'],\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    val_acc = max(history.history['val_accuracy'])\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        model.save_weights(best_model_path)  # 가중치만 저장\n",
    "\n",
    "print(f\"\\n✅ 최고 검증 정확도: {best_val_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c32fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix 시각화 함수\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# 검증 데이터 예측 후 시각화\n",
    "val_preds = model.predict(val_ds)\n",
    "val_pred_labels = np.argmax(val_preds, axis=1)\n",
    "\n",
    "plot_confusion_matrix(val_labels, val_pred_labels, list(label2id.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ddc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Grad-CAM 시각화 함수\n",
    "def display_gradcam(img_path, model, last_conv_layer_name='top_conv'):\n",
    "    img = load_img(img_path, target_size=(CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "\n",
    "    # 원본 이미지 준비\n",
    "    img_original = cv2.imread(img_path)\n",
    "    img_original = cv2.resize(img_original, (CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "    img_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # heatmap 이미지 생성 및 중첩\n",
    "    heatmap = cv2.resize(heatmap, (img_original.shape[1], img_original.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted(img_original, 0.6, heatmap_color, 0.4, 0)\n",
    "\n",
    "    # 시각화\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(img_original)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Grad-CAM\")\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 예시: 확인하고 싶은 이미지 경로 지정\n",
    "display_gradcam(image_paths[0], model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f751bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. 제출 템플릿 불러오기\n",
    "submission = pd.read_csv('./sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 2. 클래스 컬럼만 추출 (예: ['class_A', 'class_B', ..., 'class_N'])\n",
    "class_columns = submission.columns[1:]\n",
    "\n",
    "# 3. 모델 예측 (확률 값으로 반환됨, 예: (N, C))\n",
    "pred_prob = model.predict(test_ds)\n",
    "\n",
    "# 4. 예측 확률 → DataFrame 변환 + 컬럼 정렬\n",
    "pred_df = pd.DataFrame(pred_prob, columns=class_columns)\n",
    "\n",
    "# 5. 예측 결과를 제출 템플릿에 반영\n",
    "submission[class_columns] = pred_df[class_columns].values\n",
    "\n",
    "# 6. 저장\n",
    "submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"✅ 예측 결과가 baseline_submission.csv로 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
